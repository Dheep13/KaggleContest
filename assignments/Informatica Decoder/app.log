2024-11-03 20:37:24,683 - werkzeug - WARNING -  * Debugger is active!
2024-11-03 20:37:24,694 - werkzeug - INFO -  * Debugger PIN: 386-888-302
2024-11-03 20:46:52,858 - werkzeug - INFO -  * Detected change in 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\app.py', reloading
2024-11-03 20:46:52,862 - werkzeug - INFO -  * Detected change in 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\app.py', reloading
2024-11-03 20:51:03,252 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 20:51:03,255 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 20:51:15,307 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:51:15] "GET / HTTP/1.1" 200 -
2024-11-03 20:51:18,086 - __main__ - INFO - Received XML content for analysis
2024-11-03 20:51:18,087 - __main__ - DEBUG - Starting XML parsing
2024-11-03 20:51:18,091 - __main__ - ERROR - Error analyzing mapping: name 'asdict' is not defined
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 336, in analyze_mapping
    return jsonify({'mapping': mapping.to_dict()})
                               ^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 120, in to_dict
    'transformations': [t.to_dict() for t in self.transformations],
                        ^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 92, in to_dict
    'fields': [field.to_dict() for field in self.fields],
               ^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 63, in to_dict
    return {k: v for k, v in asdict(self).items() if v is not None}
                             ^^^^^^
NameError: name 'asdict' is not defined. Did you mean: 'dict'?
2024-11-03 20:51:18,111 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:51:18] "[35m[1mPOST /analyze HTTP/1.1[0m" 500 -
2024-11-03 20:54:27,631 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 20:54:27,632 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 20:54:34,291 - __main__ - INFO - Received XML content for analysis
2024-11-03 20:54:34,292 - __main__ - DEBUG - Starting XML parsing
2024-11-03 20:54:34,296 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:54:34] "POST /analyze HTTP/1.1" 200 -
2024-11-03 20:54:42,041 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist.'}, {'role': 'user', 'content': '\n        Based on the following mapping and transformation data, generate a comprehensive design document:\n        \n        Mapping Details: {\n  "mapping": {\n    "connectors": [\n      {\n        "fromfield": "o_ADDORDEL",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "ADDORDEL",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "o_USERID",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "USERID",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "o_GROUPNM",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "GROUPNM",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "ADDORDEL",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "USERID",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "GROUPNM",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "ADDORDEL",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "USERID",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "GROUPNM",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_ADDORDEL",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_USERID",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_GROUPNM",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_ADDORDEL",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_USERID",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_GROUPNM",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "LKPTRANS",\n        "frominstancetype": "Lookup Procedure",\n        "tofield": "lkp_ADDORDEL",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "lkp_ADDORDEL",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "lkp_ADDORDEL",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_ADDORDEL",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_ADDORDEL",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_USERID",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_USERID",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_GROUPNM",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_GROUPNM",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      }\n    ],\n    "description": "",\n    "name": "m_BOUPDATE_FILE_LOAD",\n    "sources": [\n      "BOUPDATE_DMP"\n    ],\n    "targets": [\n      "EXP_BOUPDATE_FILE1"\n    ],\n    "transformations": [\n      {\n        "attributes": [\n          {\n            "name": "Sql Query",\n            "value": "select * from (\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGP_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGP_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY BN Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY BN Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY BN Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY BN Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRU_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRU_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - PD BN Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - PD BN Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUPD\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - PD SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - PD SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPPD\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - FA SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - FA SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAFA\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - FA SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - FA SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAFA\')\\r\\n)  order by 2 desc"\n          },\n          {\n            "name": "User Defined Join",\n            "value": ""\n          },\n          {\n            "name": "Source Filter",\n            "value": ""\n          },\n          {\n            "name": "Number Of Sorted Ports",\n            "value": "0"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          },\n          {\n            "name": "Select Distinct",\n            "value": "NO"\n          },\n          {\n            "name": "Is Partitionable",\n            "value": "NO"\n          },\n          {\n            "name": "Pre SQL",\n            "value": ""\n          },\n          {\n            "name": "Post SQL",\n            "value": ""\n          },\n          {\n            "name": "Output is deterministic",\n            "value": "NO"\n          },\n          {\n            "name": "Output is repeatable",\n            "value": "Never"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "SQ_BOUPDATE_DMP",\n        "reusable": "NO",\n        "type": "Source Qualifier"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "USERID",\n            "expressiontype": "GENERAL",\n            "name": "USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "GROUPNM",\n            "expressiontype": "GENERAL",\n            "name": "GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "EXP_BOUPDATE_FILE",\n        "reusable": "NO",\n        "type": "Expression"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "lkp_ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "lkp_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "o_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_USERID",\n            "expressiontype": "GENERAL",\n            "name": "o_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_GROUPNM",\n            "expressiontype": "GENERAL",\n            "name": "o_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "EXP_LKP",\n        "reusable": "NO",\n        "type": "Expression"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Filter Condition",\n            "value": "iif(isnull(lkp_ADDORDEL),TRUE,FALSE)"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "lkp_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "FIL_Valid",\n        "reusable": "NO",\n        "type": "Filter"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Lookup Sql Override",\n            "value": ""\n          },\n          {\n            "name": "Lookup table name",\n            "value": "BOUPDATE_DMP"\n          },\n          {\n            "name": "Lookup Source Filter",\n            "value": ""\n          },\n          {\n            "name": "Lookup caching enabled",\n            "value": "YES"\n          },\n          {\n            "name": "Lookup policy on multiple match",\n            "value": "Use Any Value"\n          },\n          {\n            "name": "Lookup condition",\n            "value": "ADDORDEL = i_ADDORDEL AND USERID = i_USERID AND GROUPNM = i_GROUPNM"\n          },\n          {\n            "name": "Connection Information",\n            "value": "$Target"\n          },\n          {\n            "name": "Source Type",\n            "value": "Database"\n          },\n          {\n            "name": "Recache if Stale",\n            "value": "NO"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          },\n          {\n            "name": "Lookup cache directory name",\n            "value": "$PMCacheDir"\n          },\n          {\n            "name": "Lookup cache initialize",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup cache persistent",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup Data Cache Size",\n            "value": "Auto"\n          },\n          {\n            "name": "Lookup Index Cache Size",\n            "value": "Auto"\n          },\n          {\n            "name": "Dynamic Lookup Cache",\n            "value": "NO"\n          },\n          {\n            "name": "Synchronize Dynamic Cache",\n            "value": "NO"\n          },\n          {\n            "name": "Output Old Value On Update",\n            "value": "NO"\n          },\n          {\n            "name": "Update Dynamic Cache Condition",\n            "value": "TRUE"\n          },\n          {\n            "name": "Cache File Name Prefix",\n            "value": ""\n          },\n          {\n            "name": "Re-cache from lookup source",\n            "value": "NO"\n          },\n          {\n            "name": "Insert Else Update",\n            "value": "NO"\n          },\n          {\n            "name": "Update Else Insert",\n            "value": "NO"\n          },\n          {\n            "name": "Datetime Format",\n            "value": ""\n          },\n          {\n            "name": "Thousand Separator",\n            "value": "None"\n          },\n          {\n            "name": "Decimal Separator",\n            "value": "."\n          },\n          {\n            "name": "Case Sensitive String Comparison",\n            "value": "NO"\n          },\n          {\n            "name": "Null ordering",\n            "value": "Null Is Highest Value"\n          },\n          {\n            "name": "Sorted Input",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup source is static",\n            "value": "NO"\n          },\n          {\n            "name": "Pre-build lookup cache",\n            "value": "Auto"\n          },\n          {\n            "name": "Subsecond Precision",\n            "value": "6"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "ADDORDEL",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "USERID",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "GROUPNM",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "LKPTRANS",\n        "reusable": "NO",\n        "type": "Lookup Procedure"\n      }\n    ]\n  }\n}\n\n        Please include:\n        1. Architectural Overview\n        2. Source Systems\n        3. Target Systems\n        4. Transformation Details\n        5. Data Flow Description\n        6. Business Rules and Logic\n        7. Performance Considerations\n        8. Dependencies\n        9. Error Handling\n        '}], 'model': 'gpt-4o', 'max_tokens': 4000, 'temperature': 0.7}}
2024-11-03 20:54:42,398 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 20:54:42,398 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 20:54:42,429 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EB080E2B10>
2024-11-03 20:54:42,429 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EB081FB250> server_hostname='api.openai.com' timeout=5.0
2024-11-03 20:54:42,508 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EB080E0EC0>
2024-11-03 20:54:42,508 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 20:54:42,508 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 20:54:42,523 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 20:54:42,523 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 20:54:42,523 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 20:54:58,446 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:24:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14964'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'500'), (b'x-ratelimit-limit-tokens', b'30000'), (b'x-ratelimit-remaining-requests', b'499'), (b'x-ratelimit-remaining-tokens', b'21828'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'16.344s'), (b'x-request-id', b'req_e8dba6e12bc14ac0b95031f49613ab15'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=zQP6OzjG.dO9_GMlp58BmOnkeTyzXowRD9jQrHgLbik-1730647498-1.0.1.1-cOtcb4uwIuI3KvU2omdrOHqmA1K.3mGzmrivskFH6my8WZZS7qYR95o0D6cuvwonC23Z9GKt4Bp02vOWqv4R6A; path=/; expires=Sun, 03-Nov-24 15:54:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qyTbho4kLtTxVqXf32z_dMGEDg7pPcdFkjcCOTs87mM-1730647498966-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd5f71293c9a8a-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 20:54:58,446 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 20:54:58,446 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 20:54:58,446 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 20:54:58,446 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 20:54:58,446 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 20:54:58,446 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:24:58 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '14964'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '500'), ('x-ratelimit-limit-tokens', '30000'), ('x-ratelimit-remaining-requests', '499'), ('x-ratelimit-remaining-tokens', '21828'), ('x-ratelimit-reset-requests', '120ms'), ('x-ratelimit-reset-tokens', '16.344s'), ('x-request-id', 'req_e8dba6e12bc14ac0b95031f49613ab15'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=zQP6OzjG.dO9_GMlp58BmOnkeTyzXowRD9jQrHgLbik-1730647498-1.0.1.1-cOtcb4uwIuI3KvU2omdrOHqmA1K.3mGzmrivskFH6my8WZZS7qYR95o0D6cuvwonC23Z9GKt4Bp02vOWqv4R6A; path=/; expires=Sun, 03-Nov-24 15:54:58 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=qyTbho4kLtTxVqXf32z_dMGEDg7pPcdFkjcCOTs87mM-1730647498966-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd5f71293c9a8a-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 20:54:58,446 - openai._base_client - DEBUG - request_id: req_e8dba6e12bc14ac0b95031f49613ab15
2024-11-03 20:54:58,463 - __main__ - ERROR - Error generating document: create_pdf() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 366, in generate_document
    create_pdf(design_document, pdf_buffer)
TypeError: create_pdf() takes 1 positional argument but 2 were given
2024-11-03 20:54:58,472 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:54:58] "[35m[1mPOST /generate_document HTTP/1.1[0m" 500 -
2024-11-03 20:59:15,582 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 20:59:15,584 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 20:59:25,532 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:59:25] "GET / HTTP/1.1" 200 -
2024-11-03 20:59:34,448 - __main__ - INFO - Received XML content for analysis
2024-11-03 20:59:34,449 - __main__ - DEBUG - Starting XML parsing
2024-11-03 20:59:34,452 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:59:34] "POST /analyze HTTP/1.1" 200 -
2024-11-03 20:59:42,942 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist.'}, {'role': 'user', 'content': '\n        Based on the following mapping and transformation data, generate a comprehensive design document:\n        \n        Mapping Details: {\n  "mapping": {\n    "connectors": [\n      {\n        "fromfield": "o_ADDORDEL",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "ADDORDEL",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "o_USERID",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "USERID",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "o_GROUPNM",\n        "frominstance": "FIL_Valid",\n        "frominstancetype": "Filter",\n        "tofield": "GROUPNM",\n        "toinstance": "EXP_BOUPDATE_FILE1",\n        "toinstancetype": "Target Definition"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "ADDORDEL",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "USERID",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "BOUPDATE_DMP",\n        "frominstancetype": "Source Definition",\n        "tofield": "GROUPNM",\n        "toinstance": "SQ_BOUPDATE_DMP",\n        "toinstancetype": "Source Qualifier"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "ADDORDEL",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "USERID",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "SQ_BOUPDATE_DMP",\n        "frominstancetype": "Source Qualifier",\n        "tofield": "GROUPNM",\n        "toinstance": "EXP_BOUPDATE_FILE",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_ADDORDEL",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_USERID",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "o_GROUPNM",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_ADDORDEL",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "USERID",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_USERID",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "GROUPNM",\n        "frominstance": "EXP_BOUPDATE_FILE",\n        "frominstancetype": "Expression",\n        "tofield": "i_GROUPNM",\n        "toinstance": "LKPTRANS",\n        "toinstancetype": "Lookup Procedure"\n      },\n      {\n        "fromfield": "ADDORDEL",\n        "frominstance": "LKPTRANS",\n        "frominstancetype": "Lookup Procedure",\n        "tofield": "lkp_ADDORDEL",\n        "toinstance": "EXP_LKP",\n        "toinstancetype": "Expression"\n      },\n      {\n        "fromfield": "lkp_ADDORDEL",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "lkp_ADDORDEL",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_ADDORDEL",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_ADDORDEL",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_USERID",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_USERID",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      },\n      {\n        "fromfield": "o_GROUPNM",\n        "frominstance": "EXP_LKP",\n        "frominstancetype": "Expression",\n        "tofield": "o_GROUPNM",\n        "toinstance": "FIL_Valid",\n        "toinstancetype": "Filter"\n      }\n    ],\n    "description": "",\n    "name": "m_BOUPDATE_FILE_LOAD",\n    "sources": [\n      "BOUPDATE_DMP"\n    ],\n    "targets": [\n      "EXP_BOUPDATE_FILE1"\n    ],\n    "transformations": [\n      {\n        "attributes": [\n          {\n            "name": "Sql Query",\n            "value": "select * from (\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGP_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGP_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY BN Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY BN Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - AGY BN Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - AGY BN Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUAGY\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRU_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - MC SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRU_Multi_Channel\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - PD BN Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - PD BN Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'BRY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'BRUPD\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - PD SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - PD SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPPD\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - FA SG Agent\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - FA SG Agent\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGT%\' and ogpo.GenericAttribute4 <> 48 and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAFA\')\\r\\nUNION\\r\\n--AIAS Compensation Reports User Group - AGY_PU - FA SG Agency\\r\\nselect \'add\' as addordel,ogpo.NAME||\'_AIAS\' as userid,\'AIAS Compensation Reports User Group - AGY_PU - FA SG Agency\' as groupnm\\r\\nfrom cs_position ogpo\\r\\nwhere  ogpo.NAME like \'SGY%\' and ogpo.removedate = to_date(\'2200-01-01\',\'yyyy-mm-dd\')\\r\\nand ogpo.processingunitseq = (select bus.processingunitseq from cs_businessunit bus\\r\\nwhere bus.name=\'SGPAFA\')\\r\\n)  order by 2 desc"\n          },\n          {\n            "name": "User Defined Join",\n            "value": ""\n          },\n          {\n            "name": "Source Filter",\n            "value": ""\n          },\n          {\n            "name": "Number Of Sorted Ports",\n            "value": "0"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          },\n          {\n            "name": "Select Distinct",\n            "value": "NO"\n          },\n          {\n            "name": "Is Partitionable",\n            "value": "NO"\n          },\n          {\n            "name": "Pre SQL",\n            "value": ""\n          },\n          {\n            "name": "Post SQL",\n            "value": ""\n          },\n          {\n            "name": "Output is deterministic",\n            "value": "NO"\n          },\n          {\n            "name": "Output is repeatable",\n            "value": "Never"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "SQ_BOUPDATE_DMP",\n        "reusable": "NO",\n        "type": "Source Qualifier"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "USERID",\n            "expressiontype": "GENERAL",\n            "name": "USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "GROUPNM",\n            "expressiontype": "GENERAL",\n            "name": "GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "EXP_BOUPDATE_FILE",\n        "reusable": "NO",\n        "type": "Expression"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "lkp_ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "lkp_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_ADDORDEL",\n            "expressiontype": "GENERAL",\n            "name": "o_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_USERID",\n            "expressiontype": "GENERAL",\n            "name": "o_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "expression": "o_GROUPNM",\n            "expressiontype": "GENERAL",\n            "name": "o_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "EXP_LKP",\n        "reusable": "NO",\n        "type": "Expression"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Filter Condition",\n            "value": "iif(isnull(lkp_ADDORDEL),TRUE,FALSE)"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "lkp_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "o_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "FIL_Valid",\n        "reusable": "NO",\n        "type": "Filter"\n      },\n      {\n        "attributes": [\n          {\n            "name": "Lookup Sql Override",\n            "value": ""\n          },\n          {\n            "name": "Lookup table name",\n            "value": "BOUPDATE_DMP"\n          },\n          {\n            "name": "Lookup Source Filter",\n            "value": ""\n          },\n          {\n            "name": "Lookup caching enabled",\n            "value": "YES"\n          },\n          {\n            "name": "Lookup policy on multiple match",\n            "value": "Use Any Value"\n          },\n          {\n            "name": "Lookup condition",\n            "value": "ADDORDEL = i_ADDORDEL AND USERID = i_USERID AND GROUPNM = i_GROUPNM"\n          },\n          {\n            "name": "Connection Information",\n            "value": "$Target"\n          },\n          {\n            "name": "Source Type",\n            "value": "Database"\n          },\n          {\n            "name": "Recache if Stale",\n            "value": "NO"\n          },\n          {\n            "name": "Tracing Level",\n            "value": "Normal"\n          },\n          {\n            "name": "Lookup cache directory name",\n            "value": "$PMCacheDir"\n          },\n          {\n            "name": "Lookup cache initialize",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup cache persistent",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup Data Cache Size",\n            "value": "Auto"\n          },\n          {\n            "name": "Lookup Index Cache Size",\n            "value": "Auto"\n          },\n          {\n            "name": "Dynamic Lookup Cache",\n            "value": "NO"\n          },\n          {\n            "name": "Synchronize Dynamic Cache",\n            "value": "NO"\n          },\n          {\n            "name": "Output Old Value On Update",\n            "value": "NO"\n          },\n          {\n            "name": "Update Dynamic Cache Condition",\n            "value": "TRUE"\n          },\n          {\n            "name": "Cache File Name Prefix",\n            "value": ""\n          },\n          {\n            "name": "Re-cache from lookup source",\n            "value": "NO"\n          },\n          {\n            "name": "Insert Else Update",\n            "value": "NO"\n          },\n          {\n            "name": "Update Else Insert",\n            "value": "NO"\n          },\n          {\n            "name": "Datetime Format",\n            "value": ""\n          },\n          {\n            "name": "Thousand Separator",\n            "value": "None"\n          },\n          {\n            "name": "Decimal Separator",\n            "value": "."\n          },\n          {\n            "name": "Case Sensitive String Comparison",\n            "value": "NO"\n          },\n          {\n            "name": "Null ordering",\n            "value": "Null Is Highest Value"\n          },\n          {\n            "name": "Sorted Input",\n            "value": "NO"\n          },\n          {\n            "name": "Lookup source is static",\n            "value": "NO"\n          },\n          {\n            "name": "Pre-build lookup cache",\n            "value": "Auto"\n          },\n          {\n            "name": "Subsecond Precision",\n            "value": "6"\n          }\n        ],\n        "description": "",\n        "expressions": [],\n        "fields": [\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "ADDORDEL",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "USERID",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "GROUPNM",\n            "porttype": "LOOKUP/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_ADDORDEL",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "10",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_USERID",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "50",\n            "scale": "0"\n          },\n          {\n            "datatype": "nstring",\n            "defaultvalue": "",\n            "name": "i_GROUPNM",\n            "porttype": "INPUT/OUTPUT",\n            "precision": "250",\n            "scale": "0"\n          }\n        ],\n        "name": "LKPTRANS",\n        "reusable": "NO",\n        "type": "Lookup Procedure"\n      }\n    ]\n  }\n}\n\n        Please include:\n        1. Architectural Overview\n        2. Source Systems\n        3. Target Systems\n        4. Transformation Details\n        5. Data Flow Description\n        6. Business Rules and Logic\n        7. Performance Considerations\n        8. Dependencies\n        9. Error Handling\n        '}], 'model': 'gpt-4', 'max_tokens': 4000, 'temperature': 0.7}}
2024-11-03 20:59:43,247 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 20:59:43,247 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 20:59:43,311 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001ACB2D5AD50>
2024-11-03 20:59:43,313 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001ACB2C97250> server_hostname='api.openai.com' timeout=5.0
2024-11-03 20:59:43,348 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001ACB2D5AB70>
2024-11-03 20:59:43,355 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 20:59:43,356 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 20:59:43,356 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 20:59:43,358 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 20:59:43,358 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 20:59:44,237 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 03 Nov 2024 15:29:44 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'329'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'1828'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'49.032s'), (b'x-request-id', b'req_a2176233f8863ed637a58c9d3d4789b3'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=joHGSNmODC_9o9emGUrlOJqer12I0RGjTgE6rXkoxwE-1730647784-1.0.1.1-SflMYiGHKQKKfI5UVAf4DI.LhjVpoCRcvT_4VSole3ZPGibBqeXK4KbSHXoYTgQU8XxvsuJCiCqjb8M1JzruDw; path=/; expires=Sun, 03-Nov-24 15:59:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qGKWSDFbE4winIggnOypgpTH_Hx_2ygbadehdcwtabM-1730647784755-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd66c969be9a84-NAG'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 20:59:44,237 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2024-11-03 20:59:44,237 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 20:59:44,237 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 20:59:44,243 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 20:59:44,243 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 20:59:44,244 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "400 Bad Request" Headers([('date', 'Sun, 03 Nov 2024 15:29:44 GMT'), ('content-type', 'application/json'), ('content-length', '329'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '21'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '1828'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '49.032s'), ('x-request-id', 'req_a2176233f8863ed637a58c9d3d4789b3'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=joHGSNmODC_9o9emGUrlOJqer12I0RGjTgE6rXkoxwE-1730647784-1.0.1.1-SflMYiGHKQKKfI5UVAf4DI.LhjVpoCRcvT_4VSole3ZPGibBqeXK4KbSHXoYTgQU8XxvsuJCiCqjb8M1JzruDw; path=/; expires=Sun, 03-Nov-24 15:59:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=qGKWSDFbE4winIggnOypgpTH_Hx_2ygbadehdcwtabM-1730647784755-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd66c969be9a84-NAG'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 20:59:44,247 - openai._base_client - DEBUG - request_id: req_a2176233f8863ed637a58c9d3d4789b3
2024-11-03 20:59:44,247 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1025, in _request
    response.raise_for_status()
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\httpx\_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400
2024-11-03 20:59:44,247 - openai._base_client - DEBUG - Not retrying
2024-11-03 20:59:44,247 - openai._base_client - DEBUG - Re-raising status error
2024-11-03 20:59:44,256 - __main__ - ERROR - Error generating design document: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, you requested 9518 tokens (5518 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2024-11-03 20:59:44,259 - __main__ - ERROR - Error generating document: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, you requested 9518 tokens (5518 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 381, in generate_document
    design_document = generate_design_document(mapping_data)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 273, in generate_design_document
    response = client.chat.completions.create(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_utils\_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\resources\chat\completions.py", line 643, in create
    return self._post(
           ^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1266, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 942, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\openai\_base_client.py", line 1046, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 8192 tokens. However, you requested 9518 tokens (5518 in the messages, 4000 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2024-11-03 20:59:44,298 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 20:59:44] "[35m[1mPOST /generate_document HTTP/1.1[0m" 500 -
2024-11-03 21:03:37,529 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:03:37,531 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:03:47,260 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:03:47] "GET / HTTP/1.1" 200 -
2024-11-03 21:03:50,777 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:03:50,777 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:03:50,781 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:03:50] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:03:56,022 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:03:56,312 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:03:56,312 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:03:56,361 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018E5B0CCEF0>
2024-11-03 21:03:56,362 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000018E5AFF72D0> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:03:56,396 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018E5B0CCB00>
2024-11-03 21:03:56,396 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:03:56,412 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:03:56,412 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:03:56,415 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:03:56,416 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:04:12,760 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:34:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'15546'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_56aac3d6e64c7db67c85670225863219'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=C9z28C2a.4k.tko81IaYXEHB2lyg08TOJIqEXz3gS_k-1730648053-1.0.1.1-M57.8SGSGmfE0duPj5w8sfzBgf6XJqsfTV7HB45XZHUvBZVM3fq7Ma.IZ_g4CCq9z2yQbatEja3_aPn0AiozTQ; path=/; expires=Sun, 03-Nov-24 16:04:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=rzOSAp67kycVyjmaaG9Nu1FCqFnUbBsnQqdws6snWcA-1730648053290-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd6cf6f8df9a93-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:04:12,760 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:04:12,760 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:04:12,777 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:04:12,777 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:04:12,778 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:04:12,778 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:34:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '15546'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_56aac3d6e64c7db67c85670225863219'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=C9z28C2a.4k.tko81IaYXEHB2lyg08TOJIqEXz3gS_k-1730648053-1.0.1.1-M57.8SGSGmfE0duPj5w8sfzBgf6XJqsfTV7HB45XZHUvBZVM3fq7Ma.IZ_g4CCq9z2yQbatEja3_aPn0AiozTQ; path=/; expires=Sun, 03-Nov-24 16:04:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=rzOSAp67kycVyjmaaG9Nu1FCqFnUbBsnQqdws6snWcA-1730648053290-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd6cf6f8df9a93-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:04:12,780 - openai._base_client - DEBUG - request_id: req_56aac3d6e64c7db67c85670225863219
2024-11-03 21:04:12,784 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:04:12,791 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:04:12,791 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:04:12,792 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:04:12,792 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:04:12,793 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:04:12,793 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:04:25,017 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:34:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'11918'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_47142243cc892284ece2d2d155e8d5fe'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd6d5d5c989a93-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:04:25,019 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:04:25,019 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:04:25,019 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:04:25,019 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:04:25,019 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:04:25,019 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:34:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '11918', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_47142243cc892284ece2d2d155e8d5fe', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd6d5d5c989a93-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:04:25,019 - openai._base_client - DEBUG - request_id: req_47142243cc892284ece2d2d155e8d5fe
2024-11-03 21:04:25,027 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:04:25,030 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:04:25,031 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:04:25,031 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:04:25,031 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:04:25,033 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:04:25,034 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:04:42,716 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:34:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'17373'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_a66e9cf6d8d64260c6a79c65827dbde5'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd6da9dc379a93-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:04:42,730 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:04:42,730 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:04:42,734 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:04:42,734 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:04:42,734 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:04:42,734 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:34:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '17373', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_a66e9cf6d8d64260c6a79c65827dbde5', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd6da9dc379a93-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:04:42,734 - openai._base_client - DEBUG - request_id: req_a66e9cf6d8d64260c6a79c65827dbde5
2024-11-03 21:04:42,734 - __main__ - ERROR - Error generating document: name 'SimpleDocTemplate' is not defined
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 470, in generate_document
    pdf_buffer = create_pdf(design_document)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 370, in create_pdf
    doc = SimpleDocTemplate(
          ^^^^^^^^^^^^^^^^^
NameError: name 'SimpleDocTemplate' is not defined
2024-11-03 21:04:42,766 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:04:42] "[35m[1mPOST /generate_document HTTP/1.1[0m" 500 -
2024-11-03 21:08:31,333 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:08:31,333 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:08:49,545 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:08:49] "GET / HTTP/1.1" 200 -
2024-11-03 21:08:52,244 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:08:52,245 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:08:52,247 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:08:52] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:08:56,244 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:08:56,563 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:08:56,563 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:08:56,599 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AA2A247410>
2024-11-03 21:08:56,599 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002AA2A1C7850> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:08:56,647 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002AA29F6CF50>
2024-11-03 21:08:56,647 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:08:56,647 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:08:56,647 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:08:56,647 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:08:56,647 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:09:12,694 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:39:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'15706'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_488e659bf516eac3a7515a79f1ec85e0'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QkW_DahMW3fdhoBRBC90CtmnkJ2jpCjAgKkzF1KfLlM-1730648353-1.0.1.1-6LwybA.JmyBLpvcilRqvCnwYUUsr6Nd.GOrjI9mJ0lAH_MQgu95GxvQ0v31lGVaAyTfkN_03KPii_fEPeX5.Lw; path=/; expires=Sun, 03-Nov-24 16:09:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=WGh2.FHgoIjP576qLYeyDhmOjrBkkzOZwRDiTilFXbY-1730648353216-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd744b8f4231b8-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:09:12,697 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:09:12,698 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:09:12,700 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:09:12,701 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:09:12,701 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:09:12,701 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:39:13 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '15706'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_488e659bf516eac3a7515a79f1ec85e0'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QkW_DahMW3fdhoBRBC90CtmnkJ2jpCjAgKkzF1KfLlM-1730648353-1.0.1.1-6LwybA.JmyBLpvcilRqvCnwYUUsr6Nd.GOrjI9mJ0lAH_MQgu95GxvQ0v31lGVaAyTfkN_03KPii_fEPeX5.Lw; path=/; expires=Sun, 03-Nov-24 16:09:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=WGh2.FHgoIjP576qLYeyDhmOjrBkkzOZwRDiTilFXbY-1730648353216-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd744b8f4231b8-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:09:12,706 - openai._base_client - DEBUG - request_id: req_488e659bf516eac3a7515a79f1ec85e0
2024-11-03 21:09:12,718 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:09:12,718 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:09:12,718 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:09:12,718 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:09:12,727 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:09:12,728 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:09:12,730 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:09:23,245 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:39:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10144'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_86dc494b82cffe8cd2ef4658f55df5f6'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd74affbdc31b8-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:09:23,260 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:09:23,261 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:09:23,265 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:09:23,265 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:09:23,265 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:09:23,265 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:39:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10144', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_86dc494b82cffe8cd2ef4658f55df5f6', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd74affbdc31b8-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:09:23,265 - openai._base_client - DEBUG - request_id: req_86dc494b82cffe8cd2ef4658f55df5f6
2024-11-03 21:09:23,278 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:09:23,292 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:09:23,296 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:09:23,296 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:09:23,296 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:09:23,296 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:09:23,296 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:09:40,524 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:39:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'16861'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_124f33011f994d9445f65ed10397c335'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd74f21ec031b8-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:09:40,524 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:09:40,524 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:09:40,524 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:09:40,536 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:09:40,536 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:09:40,536 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:39:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '16861', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_124f33011f994d9445f65ed10397c335', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd74f21ec031b8-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:09:40,541 - openai._base_client - DEBUG - request_id: req_124f33011f994d9445f65ed10397c335
2024-11-03 21:09:40,608 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:09:40] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:15:25,871 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:15:25,874 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:15:35,471 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:15:35] "GET / HTTP/1.1" 200 -
2024-11-03 21:15:38,071 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:15:38,072 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:15:38,073 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:15:38] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:15:42,983 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:15:43,357 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:15:43,359 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:15:43,386 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022C4DB7E0C0>
2024-11-03 21:15:43,386 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000022C4DDD7850> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:15:43,427 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022C4DE25460>
2024-11-03 21:15:43,427 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:15:43,427 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:15:43,427 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:15:43,427 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:15:43,427 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:15:58,968 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:45:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14683'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_3528dcbd012748abfa02c3bc09af736f'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=B7gGE_Le2hrLWoRPgEOCGaqFq3mChKBKmyTg2Tza1TA-1730648759-1.0.1.1-tJq0YrelTz8QXdDzGPhCogqCG333.UPWA1M4JCCuwbavpoRTrkDAkOZLvo9XAcjflw0ogbjyjSRBxDqvQEq5Ug; path=/; expires=Sun, 03-Nov-24 16:15:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=5RaAm5bE_UkdvCqovI4Tc4nFDdcsYNfFWW4QjkeHsV0-1730648759496-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd7e39ebe29a89-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:15:58,972 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:15:58,972 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:15:58,980 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:15:58,983 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:15:58,983 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:15:58,983 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:45:59 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '14683'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_3528dcbd012748abfa02c3bc09af736f'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=B7gGE_Le2hrLWoRPgEOCGaqFq3mChKBKmyTg2Tza1TA-1730648759-1.0.1.1-tJq0YrelTz8QXdDzGPhCogqCG333.UPWA1M4JCCuwbavpoRTrkDAkOZLvo9XAcjflw0ogbjyjSRBxDqvQEq5Ug; path=/; expires=Sun, 03-Nov-24 16:15:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=5RaAm5bE_UkdvCqovI4Tc4nFDdcsYNfFWW4QjkeHsV0-1730648759496-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd7e39ebe29a89-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:15:58,983 - openai._base_client - DEBUG - request_id: req_3528dcbd012748abfa02c3bc09af736f
2024-11-03 21:15:59,015 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:15:59,017 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:15:59,017 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:15:59,017 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:15:59,017 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:15:59,023 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:15:59,023 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:16:09,065 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:46:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'9682'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_daa057251c3be9d025744cc65069e20b'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd7e9b5a579a89-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:16:09,066 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:16:09,066 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:16:09,066 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:16:09,066 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:16:09,066 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:16:09,066 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:46:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '9682', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_daa057251c3be9d025744cc65069e20b', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd7e9b5a579a89-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:16:09,071 - openai._base_client - DEBUG - request_id: req_daa057251c3be9d025744cc65069e20b
2024-11-03 21:16:09,079 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:16:09,083 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:16:09,083 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:16:09,083 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:16:09,083 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:16:09,083 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:16:09,083 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:16:26,982 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:46:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'17557'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_04ddf71d596100b3fd0c6342e27b431a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd7eda3dde9a89-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:16:26,982 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:16:26,982 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:16:26,982 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:16:26,982 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:16:26,982 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:16:26,995 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:46:27 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '17557', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_04ddf71d596100b3fd0c6342e27b431a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd7eda3dde9a89-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:16:26,997 - openai._base_client - DEBUG - request_id: req_04ddf71d596100b3fd0c6342e27b431a
2024-11-03 21:16:27,146 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:16:27] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:18:25,534 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:18:25,536 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:18:45,667 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:18:45] "GET / HTTP/1.1" 200 -
2024-11-03 21:18:48,298 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:18:48,298 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:18:48,301 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:18:48] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:18:52,794 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:18:53,093 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:18:53,093 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:18:53,145 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002887F6CF650>
2024-11-03 21:18:53,145 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002887F647850> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:18:53,178 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002887F2306E0>
2024-11-03 21:18:53,193 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:18:53,195 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:18:53,195 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:18:53,195 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:18:53,195 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:19:10,573 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:49:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'17025'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_ea9df57a28a3cd63a8211be1235e643e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=VZA7TPK6X0vZEY_BhJ32AFa7Oop4YHvitPG.132zoT4-1730648951-1.0.1.1-AqXsYbEzVWEdbPrYDGoRA28MIerSqB_zIdI5PFK_8xpc.t0ZXo0Tv0SftAxkPqToBS4Ml39UFMyYHgN9DZG5ig; path=/; expires=Sun, 03-Nov-24 16:19:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=E1yoL9zuUJSYsFXr8wBN96tXb.7EcWNyC_ThtyXu0hM-1730648951105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd82dbfe108eee-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:19:10,588 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:19:10,589 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:19:10,591 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:19:10,592 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:19:10,592 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:19:10,593 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:49:11 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '17025'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_ea9df57a28a3cd63a8211be1235e643e'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=VZA7TPK6X0vZEY_BhJ32AFa7Oop4YHvitPG.132zoT4-1730648951-1.0.1.1-AqXsYbEzVWEdbPrYDGoRA28MIerSqB_zIdI5PFK_8xpc.t0ZXo0Tv0SftAxkPqToBS4Ml39UFMyYHgN9DZG5ig; path=/; expires=Sun, 03-Nov-24 16:19:11 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=E1yoL9zuUJSYsFXr8wBN96tXb.7EcWNyC_ThtyXu0hM-1730648951105-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd82dbfe108eee-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:19:10,597 - openai._base_client - DEBUG - request_id: req_ea9df57a28a3cd63a8211be1235e643e
2024-11-03 21:19:10,608 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:19:10,621 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:19:10,623 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:19:10,625 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:19:10,626 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:19:10,627 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:19:10,628 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:19:20,889 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:49:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'9908'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_9b14124ac4f5de016b97dd1fa6aa9e08'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd8348eff78eee-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:19:20,905 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:19:20,907 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:19:20,908 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:19:20,908 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:19:20,909 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:19:20,909 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:49:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '9908', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_9b14124ac4f5de016b97dd1fa6aa9e08', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd8348eff78eee-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:19:20,911 - openai._base_client - DEBUG - request_id: req_9b14124ac4f5de016b97dd1fa6aa9e08
2024-11-03 21:19:20,913 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:19:20,921 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:19:20,924 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:19:20,925 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:19:20,925 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:19:20,926 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:19:20,926 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:19:36,036 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:49:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14766'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_fe59a95cd4581d535ce3c24fc7ba7ae1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd83894e6c8eee-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:19:36,053 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:19:36,053 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:19:36,053 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:19:36,053 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:19:36,053 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:19:36,053 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:49:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '14766', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_fe59a95cd4581d535ce3c24fc7ba7ae1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd83894e6c8eee-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:19:36,070 - openai._base_client - DEBUG - request_id: req_fe59a95cd4581d535ce3c24fc7ba7ae1
2024-11-03 21:19:36,138 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:19:36] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:21:38,531 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:21:38] "GET / HTTP/1.1" 200 -
2024-11-03 21:21:45,127 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:21:45,127 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:21:45,130 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:21:45] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:21:49,341 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:21:49,345 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:21:49,346 - httpcore.connection - DEBUG - close.started
2024-11-03 21:21:49,347 - httpcore.connection - DEBUG - close.complete
2024-11-03 21:21:49,348 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:21:49,391 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028808143980>
2024-11-03 21:21:49,391 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002887F647850> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:21:49,428 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002887F6FBD10>
2024-11-03 21:21:49,428 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:21:49,430 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:21:49,430 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:21:49,430 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:21:49,430 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:22:06,883 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:52:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'16646'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_dac4731379cbfaf893460deb0bc8d7aa'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd87296d669a75-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:22:06,883 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:22:06,883 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:22:06,883 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:22:06,883 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:22:06,883 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:22:06,883 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:52:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '16646', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8886', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.684s', 'x-request-id': 'req_dac4731379cbfaf893460deb0bc8d7aa', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd87296d669a75-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:22:06,904 - openai._base_client - DEBUG - request_id: req_dac4731379cbfaf893460deb0bc8d7aa
2024-11-03 21:22:06,916 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:22:06,919 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:22:06,919 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:22:06,919 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:22:06,919 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:22:06,919 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:22:06,919 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:22:16,616 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:52:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'9384'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_c72366662fef582b59933eaae3bda029'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd8796c8419a75-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:22:16,616 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:22:16,631 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:22:16,632 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:22:16,633 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:22:16,633 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:22:16,633 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:52:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '9384', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_c72366662fef582b59933eaae3bda029', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd8796c8419a75-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:22:16,639 - openai._base_client - DEBUG - request_id: req_c72366662fef582b59933eaae3bda029
2024-11-03 21:22:16,650 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:22:16,654 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:22:16,654 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:22:16,654 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:22:16,654 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:22:16,666 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:22:16,667 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:22:30,035 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:52:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'13053'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_4140c112d69f264d9f36c12b7c7a300e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd87d39d749a75-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:22:30,037 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:22:30,037 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:22:30,037 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:22:30,037 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:22:30,037 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:22:30,047 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:52:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '13053', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_4140c112d69f264d9f36c12b7c7a300e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd87d39d749a75-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:22:30,049 - openai._base_client - DEBUG - request_id: req_4140c112d69f264d9f36c12b7c7a300e
2024-11-03 21:22:30,084 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:22:30] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:28:03,129 - root - INFO - Static directories created successfully
2024-11-03 21:28:03,129 - root - INFO - Static directories created successfully
2024-11-03 21:28:03,175 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:28:03,175 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:28:12,269 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:28:12] "GET / HTTP/1.1" 200 -
2024-11-03 21:28:16,242 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:28:16,242 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:28:16,246 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:28:16] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:28:20,320 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:28:20,668 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:28:20,668 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:28:20,749 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000213C4589D90>
2024-11-03 21:28:20,751 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000213C44C7950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:28:20,801 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000213AC2C2000>
2024-11-03 21:28:20,801 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:28:20,801 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:28:20,801 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:28:20,801 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:28:20,801 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:28:35,497 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:58:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'13897'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_9439e00afc86879234b64d802c0b071c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=Wxy7coLVMhmWD9BtFYdGmtJ5MyXdhQjyHeTd9Ccgo_Y-1730649516-1.0.1.1-e78lPC7qgfNRl8PFjfI.C6uh.ZudA.IwOHs1_VcnZ8H8vJnitDjwx.4CAKHF8bfGKvdhEuMpu8p_WFwauzNmHQ; path=/; expires=Sun, 03-Nov-24 16:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=G1DZpJ.xmrbjIVPhdXEys3Gu4TKcRJddAaCXuCdK5B8-1730649516046-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd90b7886e9a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:28:35,514 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:28:35,514 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:28:35,517 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:28:35,517 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:28:35,517 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:28:35,517 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 15:58:36 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '13897'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_9439e00afc86879234b64d802c0b071c'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=Wxy7coLVMhmWD9BtFYdGmtJ5MyXdhQjyHeTd9Ccgo_Y-1730649516-1.0.1.1-e78lPC7qgfNRl8PFjfI.C6uh.ZudA.IwOHs1_VcnZ8H8vJnitDjwx.4CAKHF8bfGKvdhEuMpu8p_WFwauzNmHQ; path=/; expires=Sun, 03-Nov-24 16:28:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=G1DZpJ.xmrbjIVPhdXEys3Gu4TKcRJddAaCXuCdK5B8-1730649516046-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd90b7886e9a7e-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:28:35,517 - openai._base_client - DEBUG - request_id: req_9439e00afc86879234b64d802c0b071c
2024-11-03 21:28:35,533 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:28:35,548 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:28:35,550 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:28:35,550 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:28:35,550 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:28:35,550 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:28:35,550 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:28:43,782 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:58:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'7796'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_19edc1466ff9083eac7d4428cafd570a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd9113ba1f9a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:28:43,782 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:28:43,782 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:28:43,782 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:28:43,782 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:28:43,782 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:28:43,782 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:58:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '7796', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_19edc1466ff9083eac7d4428cafd570a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd9113ba1f9a7e-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:28:43,782 - openai._base_client - DEBUG - request_id: req_19edc1466ff9083eac7d4428cafd570a
2024-11-03 21:28:43,798 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:28:43,798 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:28:43,798 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:28:43,798 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:28:43,798 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:28:43,798 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:28:43,798 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:28:58,964 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 15:58:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14848'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'9.164s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_f262f44aa85d7dcad6aaa387248ab5c8'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd91474a849a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:28:58,964 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:28:58,964 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:28:58,964 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:28:58,964 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:28:58,964 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:28:58,964 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 15:58:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '14848', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '9.164s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_f262f44aa85d7dcad6aaa387248ab5c8', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd91474a849a7e-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:28:58,972 - openai._base_client - DEBUG - request_id: req_f262f44aa85d7dcad6aaa387248ab5c8
2024-11-03 21:28:59,020 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:28:59] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:33:22,500 - root - INFO - Static directories created successfully
2024-11-03 21:33:22,500 - root - INFO - Static directories created successfully
2024-11-03 21:33:22,549 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:33:22,551 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:33:30,079 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:33:30] "GET / HTTP/1.1" 200 -
2024-11-03 21:33:32,718 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:33:32,718 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:33:32,720 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:33:32] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:33:35,744 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:33:36,175 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:33:36,177 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:33:36,226 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000289FF479C40>
2024-11-03 21:33:36,227 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000289FF3B7950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:33:36,274 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000289FF479970>
2024-11-03 21:33:36,276 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:33:36,278 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:33:36,279 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:33:36,279 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:33:36,279 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:33:56,008 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:03:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'19414'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_e286675e4cc8b319f64c9800356c5145'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=4OjwAwvhi7r06hqkgtWORsYPzeW5kLBLXW5KTaV_M1M-1730649836-1.0.1.1-d5ngs2qcLMKMTZTpCiUTXOtdsokDJaK8eHo4riuXzXtS86yE8FS2VOoqEi.LSFgbBituaxANoRKgVKgOzKC4yg; path=/; expires=Sun, 03-Nov-24 16:33:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=iftvQGZo0_ZyXSARCyGnsUWwUDDZdkxlqpPnSzA7DXc-1730649836541-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd986b4b028ef1-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:33:56,009 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:33:56,009 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:33:56,009 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:33:56,017 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:33:56,019 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:33:56,019 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 16:03:56 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '19414'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_e286675e4cc8b319f64c9800356c5145'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=4OjwAwvhi7r06hqkgtWORsYPzeW5kLBLXW5KTaV_M1M-1730649836-1.0.1.1-d5ngs2qcLMKMTZTpCiUTXOtdsokDJaK8eHo4riuXzXtS86yE8FS2VOoqEi.LSFgbBituaxANoRKgVKgOzKC4yg; path=/; expires=Sun, 03-Nov-24 16:33:56 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=iftvQGZo0_ZyXSARCyGnsUWwUDDZdkxlqpPnSzA7DXc-1730649836541-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcd986b4b028ef1-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:33:56,024 - openai._base_client - DEBUG - request_id: req_e286675e4cc8b319f64c9800356c5145
2024-11-03 21:33:56,037 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:33:56,047 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:33:56,049 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:33:56,051 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:33:56,053 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:33:56,057 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:33:56,058 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:34:06,456 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:04:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10066'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_7edd0c2764477737997f81d7fde2e7e7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd98e6df058ef1-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:34:06,456 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:34:06,456 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:34:06,456 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:34:06,456 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:34:06,456 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:34:06,456 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:04:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10066', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_7edd0c2764477737997f81d7fde2e7e7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd98e6df058ef1-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:34:06,470 - openai._base_client - DEBUG - request_id: req_7edd0c2764477737997f81d7fde2e7e7
2024-11-03 21:34:06,475 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:34:06,491 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:34:06,494 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:34:06,497 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:34:06,497 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:34:06,502 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:34:06,502 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:34:24,989 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:04:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'18178'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_796fc5608f1211d8e4b6230674d06d43'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcd99282add8ef1-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:34:24,989 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:34:24,989 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:34:24,989 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:34:25,001 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:34:25,002 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:34:25,003 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:04:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '18178', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_796fc5608f1211d8e4b6230674d06d43', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcd99282add8ef1-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:34:25,006 - openai._base_client - DEBUG - request_id: req_796fc5608f1211d8e4b6230674d06d43
2024-11-03 21:34:25,086 - __main__ - ERROR - Error removing temporary file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\static\\informatica_mapping_doc_20241103_213425.pdf'
2024-11-03 21:34:25,086 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:34:25] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:47:25,005 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:47:25] "GET / HTTP/1.1" 200 -
2024-11-03 21:47:27,691 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:47:27,692 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:47:27,695 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:47:27] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:47:31,220 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:47:31,228 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:47:31,230 - httpcore.connection - DEBUG - close.started
2024-11-03 21:47:31,236 - httpcore.connection - DEBUG - close.complete
2024-11-03 21:47:31,239 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:47:31,297 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002898A054620>
2024-11-03 21:47:31,298 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000289FF3B7950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:47:31,347 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000289FF47BD10>
2024-11-03 21:47:31,350 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:47:31,352 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:47:31,353 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:47:31,355 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:47:31,355 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:47:44,329 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:17:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'12661'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_cdfc5ebe552717245bfae8f8edcdf213'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdacce9f173e4c-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:47:44,348 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:47:44,348 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:47:44,348 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:47:44,348 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:47:44,348 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:47:44,348 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:17:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '12661', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8886', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.684s', 'x-request-id': 'req_cdfc5ebe552717245bfae8f8edcdf213', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdacce9f173e4c-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:47:44,362 - openai._base_client - DEBUG - request_id: req_cdfc5ebe552717245bfae8f8edcdf213
2024-11-03 21:47:44,378 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:47:44,378 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:47:44,378 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:47:44,378 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:47:44,378 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:47:44,395 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:47:44,395 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:47:55,460 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:17:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10762'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_7e8d14ba2cb1add10489342db1ac70fe'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdad200bb43e4c-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:47:55,477 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:47:55,477 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:47:55,477 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:47:55,477 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:47:55,477 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:47:55,477 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:17:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10762', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_7e8d14ba2cb1add10489342db1ac70fe', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdad200bb43e4c-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:47:55,477 - openai._base_client - DEBUG - request_id: req_7e8d14ba2cb1add10489342db1ac70fe
2024-11-03 21:47:55,494 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:47:55,508 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:47:55,510 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:47:55,512 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:47:55,512 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:47:55,517 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:47:55,517 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:48:08,991 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:18:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'13182'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_553772de88bae9aa8c4a7657a8e85a49'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdad658f863e4c-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:48:09,008 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:48:09,013 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:48:09,013 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:48:09,013 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:48:09,013 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:48:09,013 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:18:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '13182', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_553772de88bae9aa8c4a7657a8e85a49', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdad658f863e4c-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:48:09,013 - openai._base_client - DEBUG - request_id: req_553772de88bae9aa8c4a7657a8e85a49
2024-11-03 21:48:09,075 - __main__ - ERROR - Error removing temporary file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\static\\informatica_mapping_doc_20241103_214809.pdf'
2024-11-03 21:48:09,082 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:48:09] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:51:06,737 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:51:06] "GET / HTTP/1.1" 200 -
2024-11-03 21:51:09,218 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:51:09,218 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:51:09,222 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:51:09] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:51:19,997 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:51:19,999 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:51:20,002 - httpcore.connection - DEBUG - close.started
2024-11-03 21:51:20,002 - httpcore.connection - DEBUG - close.complete
2024-11-03 21:51:20,003 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:51:20,033 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002898A058F80>
2024-11-03 21:51:20,033 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000289FF3B7950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:51:20,077 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002898A057260>
2024-11-03 21:51:20,077 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:51:20,082 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:51:20,083 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:51:20,084 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:51:20,084 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:51:35,816 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:21:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'15395'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_897461726f9f716ac11a896ee5a23175'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=pXJnkqL11Bt7nJWWlEGX8n9lu03fk3nWvT6cHSCkFzU-1730650896-1.0.1.1-z5fXlZwwWGpR4u1amSRtfMFPT61wtjiw0mtxMnPvVhtejAYSO.s6b93wwHGmo84jw4hXIP2g8ge4A1IBdBbZPA; path=/; expires=Sun, 03-Nov-24 16:51:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb2641cf93c58-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:51:35,830 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:51:35,830 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:51:35,830 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:51:35,845 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:51:35,847 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:51:35,848 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:21:36 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '15395', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8886', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.684s', 'x-request-id': 'req_897461726f9f716ac11a896ee5a23175', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=pXJnkqL11Bt7nJWWlEGX8n9lu03fk3nWvT6cHSCkFzU-1730650896-1.0.1.1-z5fXlZwwWGpR4u1amSRtfMFPT61wtjiw0mtxMnPvVhtejAYSO.s6b93wwHGmo84jw4hXIP2g8ge4A1IBdBbZPA; path=/; expires=Sun, 03-Nov-24 16:51:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb2641cf93c58-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:51:35,850 - openai._base_client - DEBUG - request_id: req_897461726f9f716ac11a896ee5a23175
2024-11-03 21:51:35,867 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:51:35,867 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:51:35,885 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:51:35,889 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:51:35,889 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:51:35,897 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:51:35,902 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:51:43,851 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:21:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'7640'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_678428aaa031013c3566189f9e4f6a5c'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb2c6e9fe3c58-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:51:43,853 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:51:43,853 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:51:43,853 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:51:43,853 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:51:43,853 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:51:43,853 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:21:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '7640', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_678428aaa031013c3566189f9e4f6a5c', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb2c6e9fe3c58-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:51:43,853 - openai._base_client - DEBUG - request_id: req_678428aaa031013c3566189f9e4f6a5c
2024-11-03 21:51:43,861 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:51:43,862 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:51:43,867 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:51:43,869 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:51:43,871 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:51:43,873 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:51:43,874 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:51:58,893 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:21:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14715'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'9.321s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_8019addb54371adfa4be3a29b8f977f1'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb2f8cc703c58-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:51:58,893 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:51:58,893 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:51:58,893 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:51:58,893 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:51:58,893 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:51:58,893 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:21:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '14715', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '9.321s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_8019addb54371adfa4be3a29b8f977f1', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb2f8cc703c58-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:51:58,907 - openai._base_client - DEBUG - request_id: req_8019addb54371adfa4be3a29b8f977f1
2024-11-03 21:51:58,962 - __main__ - ERROR - Error removing temporary file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\static\\informatica_mapping_doc_20241103_215158.pdf'
2024-11-03 21:51:58,982 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:51:58] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:55:04,116 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:55:04] "GET / HTTP/1.1" 200 -
2024-11-03 21:55:06,449 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:55:06,450 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:55:06,455 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:55:06] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:55:10,717 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:55:10,722 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:55:10,724 - httpcore.connection - DEBUG - close.started
2024-11-03 21:55:10,725 - httpcore.connection - DEBUG - close.complete
2024-11-03 21:55:10,726 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:55:10,784 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002898A05BB30>
2024-11-03 21:55:10,786 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x00000289FF3B7950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:55:10,820 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000289FF3DECC0>
2024-11-03 21:55:10,820 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:55:10,820 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:55:10,835 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:55:10,835 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:55:10,836 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:55:26,185 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:25:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'14360'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_be4b937bafe9ba6ded8b0b66b47717da'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb8064bfb9a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:55:26,185 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:55:26,185 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:55:26,185 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:55:26,185 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:55:26,185 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:55:26,196 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:25:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '14360', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8886', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.684s', 'x-request-id': 'req_be4b937bafe9ba6ded8b0b66b47717da', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb8064bfb9a7e-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:55:26,197 - openai._base_client - DEBUG - request_id: req_be4b937bafe9ba6ded8b0b66b47717da
2024-11-03 21:55:26,207 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:55:26,213 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:55:26,215 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:55:26,220 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:55:26,222 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:55:26,224 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:55:26,226 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:55:37,694 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:25:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'11133'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_5cfd069589138077b1246a3212625d4a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb8667ea49a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:55:37,704 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:55:37,704 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:55:37,704 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:55:37,704 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:55:37,704 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:55:37,704 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:25:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '11133', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_5cfd069589138077b1246a3212625d4a', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb8667ea49a7e-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:55:37,704 - openai._base_client - DEBUG - request_id: req_5cfd069589138077b1246a3212625d4a
2024-11-03 21:55:37,716 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:55:37,723 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:55:37,725 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:55:37,725 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:55:37,725 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:55:37,725 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:55:37,725 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:55:50,944 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:25:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'12907'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_efb8beda7991828028cf60dfb1339672'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdb8ae6c849a7e-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:55:50,944 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:55:50,944 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:55:50,944 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:55:50,944 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:55:50,944 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:55:50,958 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:25:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '12907', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_efb8beda7991828028cf60dfb1339672', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdb8ae6c849a7e-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:55:50,963 - openai._base_client - DEBUG - request_id: req_efb8beda7991828028cf60dfb1339672
2024-11-03 21:55:51,000 - __main__ - ERROR - Error removing temporary file: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\Users\\DeepanShanmugam\\OneDrive - MuniConS GmbH\\Documents\\Visual Studio Code\\49_DS_PET_PROJECT\\Informatica Decoder\\static\\informatica_mapping_doc_20241103_215550.pdf'
2024-11-03 21:55:51,010 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:55:51] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 21:58:32,613 - root - INFO - Static directories created successfully
2024-11-03 21:58:32,625 - root - INFO - Static directories created successfully
2024-11-03 21:58:32,696 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 21:58:32,699 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 21:58:33,437 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:58:33] "GET / HTTP/1.1" 200 -
2024-11-03 21:58:36,433 - __main__ - INFO - Received XML content for analysis
2024-11-03 21:58:36,434 - __main__ - DEBUG - Starting XML parsing
2024-11-03 21:58:36,436 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:58:36] "POST /analyze HTTP/1.1" 200 -
2024-11-03 21:58:40,244 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:58:40,565 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:58:40,565 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 21:58:40,623 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002753153B200>
2024-11-03 21:58:40,623 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027531687950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 21:58:40,665 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000275315569C0>
2024-11-03 21:58:40,666 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:58:40,668 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:58:40,668 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:58:40,669 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:58:40,670 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:58:56,598 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:28:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'15128'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_fe04824cc2d7ccb88e5889a1ae8b18da'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=OcEP3B2qZgmaBYRgezhGhv7kSjhy6mpI33NLvJ9l_oM-1730651337-1.0.1.1-pBDBhIenooqguJtOc5eG1Y4IuGBOV2S6BC66lh5XBUHTKZ66B9xzBailNaOxXiARJ9HlhmrJc8xh6qIj4fp4Qg; path=/; expires=Sun, 03-Nov-24 16:58:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=9mhq7pcXnVaEoWv6AKuLM8n_nrSE5779DFGn.XmxTys-1730651337156-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdbd25c8a19a9b-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:58:56,598 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:58:56,598 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:58:56,598 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:58:56,598 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:58:56,613 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:58:56,614 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 16:28:57 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '15128'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_fe04824cc2d7ccb88e5889a1ae8b18da'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=OcEP3B2qZgmaBYRgezhGhv7kSjhy6mpI33NLvJ9l_oM-1730651337-1.0.1.1-pBDBhIenooqguJtOc5eG1Y4IuGBOV2S6BC66lh5XBUHTKZ66B9xzBailNaOxXiARJ9HlhmrJc8xh6qIj4fp4Qg; path=/; expires=Sun, 03-Nov-24 16:58:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=9mhq7pcXnVaEoWv6AKuLM8n_nrSE5779DFGn.XmxTys-1730651337156-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcdbd25c8a19a9b-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 21:58:56,619 - openai._base_client - DEBUG - request_id: req_fe04824cc2d7ccb88e5889a1ae8b18da
2024-11-03 21:58:56,635 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:58:56,639 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:58:56,682 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:58:56,685 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:58:56,685 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:58:56,699 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:58:56,703 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:59:07,112 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:29:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10092'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_94a20bd22a52ec13d51401228c87920d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdbd89f91a9a9b-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:59:07,112 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:59:07,112 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:59:07,112 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:59:07,112 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:59:07,112 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:59:07,112 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:29:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10092', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_94a20bd22a52ec13d51401228c87920d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdbd89f91a9a9b-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:59:07,112 - openai._base_client - DEBUG - request_id: req_94a20bd22a52ec13d51401228c87920d
2024-11-03 21:59:07,127 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 21:59:07,143 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 21:59:07,143 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 21:59:07,143 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 21:59:07,143 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 21:59:07,143 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 21:59:07,143 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 21:59:23,682 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:29:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'16224'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_b16d00ad8707ed0d7d4efa55812707e7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdbdcb4bc79a9b-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 21:59:23,682 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 21:59:23,682 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 21:59:23,693 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 21:59:23,693 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 21:59:23,693 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 21:59:23,693 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:29:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '16224', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_b16d00ad8707ed0d7d4efa55812707e7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdbdcb4bc79a9b-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 21:59:23,700 - openai._base_client - DEBUG - request_id: req_b16d00ad8707ed0d7d4efa55812707e7
2024-11-03 21:59:23,743 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 21:59:23] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 22:04:50,193 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:04:50] "GET / HTTP/1.1" 200 -
2024-11-03 22:04:52,436 - __main__ - INFO - Received XML content for analysis
2024-11-03 22:04:52,436 - __main__ - DEBUG - Starting XML parsing
2024-11-03 22:04:52,437 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:04:52] "POST /analyze HTTP/1.1" 200 -
2024-11-03 22:04:56,407 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_BOUPDATE_FILE_LOAD",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:04:56,410 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:04:56,411 - httpcore.connection - DEBUG - close.started
2024-11-03 22:04:56,413 - httpcore.connection - DEBUG - close.complete
2024-11-03 22:04:56,414 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 22:04:56,470 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027531AE0BC0>
2024-11-03 22:04:56,470 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x0000027531687950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 22:04:56,521 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000027531AE0A70>
2024-11-03 22:04:56,521 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:04:56,521 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:04:56,521 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:04:56,521 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:04:56,521 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:05:08,813 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:35:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'11975'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_2d96604198f223374aceb3c9b5aa53c7'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdc652fba94478-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:05:08,817 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:05:08,817 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:05:08,817 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:05:08,817 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:05:08,817 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:05:08,817 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:35:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '11975', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8886', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.684s', 'x-request-id': 'req_2d96604198f223374aceb3c9b5aa53c7', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdc652fba94478-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:05:08,823 - openai._base_client - DEBUG - request_id: req_2d96604198f223374aceb3c9b5aa53c7
2024-11-03 22:05:08,826 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['BOUPDATE_DMP']\n                Targets: ['EXP_BOUPDATE_FILE1']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:05:08,826 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:05:08,830 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:05:08,832 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:05:08,833 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:05:08,833 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:05:08,834 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:05:19,479 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:35:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10350'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8884'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.696s'), (b'x-request-id', b'req_9e1f821b83bed7b8f4e92bdb8e8a5110'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdc69fdf5e4478-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:05:19,495 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:05:19,496 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:05:19,496 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:05:19,496 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:05:19,496 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:05:19,496 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:35:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10350', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8884', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.696s', 'x-request-id': 'req_9e1f821b83bed7b8f4e92bdb8e8a5110', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdc69fdf5e4478-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:05:19,505 - openai._base_client - DEBUG - request_id: req_9e1f821b83bed7b8f4e92bdb8e8a5110
2024-11-03 22:05:19,505 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_BOUPDATE_DMP",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXP_BOUPDATE_FILE",\n    "type": "Expression"\n  },\n  {\n    "name": "EXP_LKP",\n    "type": "Expression"\n  },\n  {\n    "name": "FIL_Valid",\n    "type": "Filter"\n  },\n  {\n    "name": "LKPTRANS",\n    "type": "Lookup Procedure"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:05:19,512 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:05:19,514 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:05:19,516 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:05:19,517 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:05:19,518 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:05:19,521 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:05:37,160 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:35:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'17327'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8831'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'7.014s'), (b'x-request-id', b'req_165648b3c3190983c6115fec3fd9e77e'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdc6e2aa604478-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:05:37,160 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:05:37,160 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:05:37,160 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:05:37,160 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:05:37,160 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:05:37,160 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:35:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '17327', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8831', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '7.014s', 'x-request-id': 'req_165648b3c3190983c6115fec3fd9e77e', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdc6e2aa604478-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:05:37,160 - openai._base_client - DEBUG - request_id: req_165648b3c3190983c6115fec3fd9e77e
2024-11-03 22:05:37,194 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:05:37] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 22:06:33,483 - root - INFO - Static directories created successfully
2024-11-03 22:06:33,499 - root - INFO - Static directories created successfully
2024-11-03 22:06:33,552 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:06:33,567 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:06:45,699 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:06:45] "GET / HTTP/1.1" 200 -
2024-11-03 22:06:45,792 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:06:45] "[33mGET /main.js HTTP/1.1[0m" 404 -
2024-11-03 22:06:57,800 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:06:57] "GET / HTTP/1.1" 200 -
2024-11-03 22:06:57,858 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:06:57] "[33mGET /main.js HTTP/1.1[0m" 404 -
2024-11-03 22:07:02,769 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:07:02] "GET / HTTP/1.1" 200 -
2024-11-03 22:07:02,814 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:07:02] "[33mGET /main.js HTTP/1.1[0m" 404 -
2024-11-03 22:07:21,708 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:07:21] "GET / HTTP/1.1" 200 -
2024-11-03 22:07:21,765 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:07:21] "[33mGET /main.js HTTP/1.1[0m" 404 -
2024-11-03 22:11:14,469 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:11:14] "GET / HTTP/1.1" 200 -
2024-11-03 22:11:14,504 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:11:14] "[33mGET /main.js HTTP/1.1[0m" 404 -
2024-11-03 22:11:24,341 - root - INFO - Static directories created successfully
2024-11-03 22:11:24,351 - root - INFO - Static directories created successfully
2024-11-03 22:11:24,383 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:11:24,386 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:11:28,706 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:11:28] "GET / HTTP/1.1" 200 -
2024-11-03 22:11:29,057 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:11:29] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-03 22:11:32,353 - __main__ - INFO - Received XML content for analysis
2024-11-03 22:11:32,355 - __main__ - DEBUG - Starting XML parsing
2024-11-03 22:11:32,362 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:11:32] "POST /analyze HTTP/1.1" 200 -
2024-11-03 22:11:52,726 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_IN_APF_CPFTXF_LIMIT",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:11:53,156 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:11:53,156 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 22:11:53,212 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CA219DFCB0>
2024-11-03 22:11:53,212 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000002CA21917950> server_hostname='api.openai.com' timeout=5.0
2024-11-03 22:11:53,288 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002CA219DFA40>
2024-11-03 22:11:53,288 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:11:53,288 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:11:53,288 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:11:53,302 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:11:53,303 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:12:10,170 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:42:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'16559'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_a9c7bbbdb6954f4bb72bb679b4ba4f2d'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.C2Q2YCzIItnpG1lPOBfWGJR38AUqXhJyfo0tYwqCuA-1730652130-1.0.1.1-51QQku4Wlkvqzo54GdhIELxRFz7t8aSnLZ9HjG_a_WJmB8yDEI.h0b1SLL_z8RX40rQWTStsl6ccRUKs0.56Dw; path=/; expires=Sun, 03-Nov-24 17:12:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=.HEs.K90D.xF_bVb5ufuC0jTsdAGK715yoEPONzwDts-1730652130727-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdd07fcc54409f-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:12:10,171 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:12:10,171 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:12:10,183 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:12:10,183 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:12:10,183 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:12:10,190 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 16:42:10 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '16559'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_a9c7bbbdb6954f4bb72bb679b4ba4f2d'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=.C2Q2YCzIItnpG1lPOBfWGJR38AUqXhJyfo0tYwqCuA-1730652130-1.0.1.1-51QQku4Wlkvqzo54GdhIELxRFz7t8aSnLZ9HjG_a_WJmB8yDEI.h0b1SLL_z8RX40rQWTStsl6ccRUKs0.56Dw; path=/; expires=Sun, 03-Nov-24 17:12:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=.HEs.K90D.xF_bVb5ufuC0jTsdAGK715yoEPONzwDts-1730652130727-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcdd07fcc54409f-BOM'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 22:12:10,202 - openai._base_client - DEBUG - request_id: req_a9c7bbbdb6954f4bb72bb679b4ba4f2d
2024-11-03 22:12:10,222 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['tblAPFCPFBTxfLimit']\n                Targets: ['IN_APF_CPFB_TXF_LIMIT']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:12:10,234 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:12:10,234 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:12:10,234 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:12:10,234 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:12:10,234 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:12:10,234 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:12:23,047 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:42:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'12495'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8882'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.708s'), (b'x-request-id', b'req_758fbee7c0f4870ce003d708c656b419'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdd0e9a9ca409f-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:12:23,062 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:12:23,065 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:12:23,065 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:12:23,069 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:12:23,069 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:12:23,069 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:42:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '12495', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8882', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.708s', 'x-request-id': 'req_758fbee7c0f4870ce003d708c656b419', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdd0e9a9ca409f-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:12:23,069 - openai._base_client - DEBUG - request_id: req_758fbee7c0f4870ce003d708c656b419
2024-11-03 22:12:23,086 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_tblAPFCPFBTxfLimit",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXPTRANS",\n    "type": "Expression"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:12:23,097 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:12:23,097 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:12:23,097 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:12:23,097 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:12:23,097 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:12:23,097 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:12:35,262 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:42:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'11835'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8876'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.744s'), (b'x-request-id', b'req_c6cae4a304876579a9f03499c5b65812'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdd13a1ea9409f-BOM'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:12:35,280 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:12:35,280 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:12:35,280 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:12:35,280 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:12:35,280 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:12:35,280 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:42:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '11835', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8876', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.744s', 'x-request-id': 'req_c6cae4a304876579a9f03499c5b65812', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdd13a1ea9409f-BOM', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:12:35,296 - openai._base_client - DEBUG - request_id: req_c6cae4a304876579a9f03499c5b65812
2024-11-03 22:12:35,297 - root - ERROR - Error generating design document: name 'generate_pdf_from_text' is not defined
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 513, in generate_document
    pdf_data = generate_pdf_from_text(design_document)  # Assume this function creates the PDF
               ^^^^^^^^^^^^^^^^^^^^^^
NameError: name 'generate_pdf_from_text' is not defined
2024-11-03 22:12:35,318 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:12:35] "[31m[1mPOST /generate_document HTTP/1.1[0m" 400 -
2024-11-03 22:13:50,555 - root - INFO - Static directories created successfully
2024-11-03 22:13:50,577 - root - INFO - Static directories created successfully
2024-11-03 22:13:50,679 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:13:50,682 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:20:23,767 - root - INFO - Static directories created successfully
2024-11-03 22:20:23,767 - root - INFO - Static directories created successfully
2024-11-03 22:20:23,824 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:20:23,824 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:20:37,156 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:20:37] "GET / HTTP/1.1" 200 -
2024-11-03 22:20:37,267 - werkzeug - INFO - 192.168.29.219 - - [03/Nov/2024 22:20:37] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-03 22:20:48,694 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:20:48] "GET / HTTP/1.1" 200 -
2024-11-03 22:20:48,798 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:20:48] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-03 22:20:55,038 - __main__ - INFO - Received XML content for analysis
2024-11-03 22:20:55,053 - __main__ - DEBUG - Starting XML parsing
2024-11-03 22:20:55,053 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:20:55] "POST /analyze HTTP/1.1" 200 -
2024-11-03 22:21:12,800 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Based on this mapping data, provide a concise architectural overview:\n                {\n  "name": "m_IN_APF_CPFTXF_LIMIT",\n  "description": ""\n}\n                \n                Include:\n                - High-level architecture\n                - Purpose of the mapping\n                - Key components\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:21:13,210 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:21:13,210 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None
2024-11-03 22:21:13,260 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C445C3AC00>
2024-11-03 22:21:13,262 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C445B77A50> server_hostname='api.openai.com' timeout=5.0
2024-11-03 22:21:13,347 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C445C3A3C0>
2024-11-03 22:21:13,359 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:21:13,361 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:21:13,362 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:21:13,362 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:21:13,362 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:21:29,375 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:51:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'15212'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8886'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.684s'), (b'x-request-id', b'req_a891280ea0c36b153840d28cb6eec38a'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QlwidyLvhLTzk7ez3_tESqvCa72eajSYs_S4pda37Po-1730652689-1.0.1.1-LhAS3FK5mhP2P_trGoy3DsdVGUW2PduYVpZFP8xjYRJ.RWgXZr_iVua9KzSz0QYn.wYGC9LQpgytpaQjsnyFKA; path=/; expires=Sun, 03-Nov-24 17:21:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=CZqrLGvljvIzdZL9U.r0sE5J0OJohNcHTW.53.nNPV8-1730652689946-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdde2c3dbc9a7d-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:21:29,392 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:21:29,392 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:21:29,392 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:21:29,392 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:21:29,392 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:21:29,407 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Sun, 03 Nov 2024 16:51:29 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'user-bowourxs9kf4dtgoqm5l6y7f'), ('openai-processing-ms', '15212'), ('openai-version', '2020-10-01'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '8886'), ('x-ratelimit-reset-requests', '8.64s'), ('x-ratelimit-reset-tokens', '6.684s'), ('x-request-id', 'req_a891280ea0c36b153840d28cb6eec38a'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=QlwidyLvhLTzk7ez3_tESqvCa72eajSYs_S4pda37Po-1730652689-1.0.1.1-LhAS3FK5mhP2P_trGoy3DsdVGUW2PduYVpZFP8xjYRJ.RWgXZr_iVua9KzSz0QYn.wYGC9LQpgytpaQjsnyFKA; path=/; expires=Sun, 03-Nov-24 17:21:29 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=CZqrLGvljvIzdZL9U.r0sE5J0OJohNcHTW.53.nNPV8-1730652689946-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '8dcdde2c3dbc9a7d-NAG'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2024-11-03 22:21:29,408 - openai._base_client - DEBUG - request_id: req_a891280ea0c36b153840d28cb6eec38a
2024-11-03 22:21:29,441 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': "\n                Describe the source and target systems for this mapping:\n                Sources: ['tblAPFCPFBTxfLimit']\n                Targets: ['IN_APF_CPFB_TXF_LIMIT']\n                \n                Include:\n                - Source systems overview\n                - Target systems overview\n                - Data flow direction\n                Maximum 300 words.\n                "}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:21:29,441 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:21:29,441 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:21:29,441 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:21:29,441 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:21:29,456 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:21:29,460 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:21:39,873 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:51:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'10104'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8882'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.708s'), (b'x-request-id', b'req_0cc42f86dd5a40f59329e7d1faf9b2bf'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdde90cf3c9a7d-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:21:39,874 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:21:39,874 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:21:39,874 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:21:39,874 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:21:39,874 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:21:39,874 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:51:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '10104', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8882', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.708s', 'x-request-id': 'req_0cc42f86dd5a40f59329e7d1faf9b2bf', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdde90cf3c9a7d-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:21:39,891 - openai._base_client - DEBUG - request_id: req_0cc42f86dd5a40f59329e7d1faf9b2bf
2024-11-03 22:21:39,893 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'You are a data integration specialist writing a technical document section.'}, {'role': 'user', 'content': '\n                Analyze these transformations:\n                [\n  {\n    "name": "SQ_tblAPFCPFBTxfLimit",\n    "type": "Source Qualifier"\n  },\n  {\n    "name": "EXPTRANS",\n    "type": "Expression"\n  }\n]\n                \n                Include:\n                - Key transformations\n                - Data manipulation steps\n                - Critical operations\n                Maximum 500 words.\n                '}], 'model': 'gpt-4', 'max_tokens': 1000, 'temperature': 0.7}}
2024-11-03 22:21:39,908 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2024-11-03 22:21:39,908 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2024-11-03 22:21:39,908 - httpcore.http11 - DEBUG - send_request_headers.complete
2024-11-03 22:21:39,908 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2024-11-03 22:21:39,908 - httpcore.http11 - DEBUG - send_request_body.complete
2024-11-03 22:21:39,923 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2024-11-03 22:21:53,895 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 03 Nov 2024 16:51:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-organization', b'user-bowourxs9kf4dtgoqm5l6y7f'), (b'openai-processing-ms', b'13657'), (b'openai-version', b'2020-10-01'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'8876'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'6.744s'), (b'x-request-id', b'req_83944082485f2e0458c12784412fdc90'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8dcdded23dd89a7d-NAG'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2024-11-03 22:21:53,898 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"
2024-11-03 22:21:53,900 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2024-11-03 22:21:53,902 - httpcore.http11 - DEBUG - receive_response_body.complete
2024-11-03 22:21:53,902 - httpcore.http11 - DEBUG - response_closed.started
2024-11-03 22:21:53,903 - httpcore.http11 - DEBUG - response_closed.complete
2024-11-03 22:21:53,903 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers({'date': 'Sun, 03 Nov 2024 16:51:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-expose-headers': 'X-Request-ID', 'openai-organization': 'user-bowourxs9kf4dtgoqm5l6y7f', 'openai-processing-ms': '13657', 'openai-version': '2020-10-01', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '10000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '8876', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '6.744s', 'x-request-id': 'req_83944082485f2e0458c12784412fdc90', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8dcdded23dd89a7d-NAG', 'content-encoding': 'gzip', 'alt-svc': 'h3=":443"; ma=86400'})
2024-11-03 22:21:53,905 - openai._base_client - DEBUG - request_id: req_83944082485f2e0458c12784412fdc90
2024-11-03 22:21:53,926 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:21:53] "POST /generate_document HTTP/1.1" 200 -
2024-11-03 22:28:12,174 - root - INFO - Static directories created successfully
2024-11-03 22:28:12,190 - root - INFO - Static directories created successfully
2024-11-03 22:28:12,281 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:28:12,284 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:33:16,935 - root - INFO - Static directories created successfully
2024-11-03 22:33:16,952 - root - INFO - Static directories created successfully
2024-11-03 22:33:17,001 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.29.219:5000
2024-11-03 22:33:17,001 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-03 22:33:24,168 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:33:24] "GET / HTTP/1.1" 200 -
2024-11-03 22:33:24,532 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:33:24] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-03 22:33:35,929 - __main__ - INFO - Received XML content for analysis
2024-11-03 22:33:35,934 - __main__ - DEBUG - Starting XML parsing
2024-11-03 22:33:35,943 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:33:35] "POST /analyze HTTP/1.1" 200 -
2024-11-03 22:33:40,937 - root - ERROR - Error generating design document: No wkhtmltopdf executable found: "b''"
If this file exists please check that this process can read it or you can pass path to it manually in method call, check README. Otherwise please install wkhtmltopdf - https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf
Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\pdfkit\configuration.py", line 35, in __init__
    with open(self.wkhtmltopdf) as f:
         ^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\DeepanShanmugam\OneDrive - MuniConS GmbH\Documents\Visual Studio Code\49_DS_PET_PROJECT\Informatica Decoder\app.py", line 574, in generate_document
    pdfkit.from_string(design_document_html, pdf_path, options=options)
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\pdfkit\api.py", line 72, in from_string
    r = PDFKit(input, 'string', options=options, toc=toc, cover=cover, css=css,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\pdfkit\pdfkit.py", line 45, in __init__
    self.configuration = (Configuration() if configuration is None
                          ^^^^^^^^^^^^^^^
  File "C:\Users\DeepanShanmugam\AppData\Local\Programs\Python\Python312\Lib\site-packages\pdfkit\configuration.py", line 38, in __init__
    raise IOError('No wkhtmltopdf executable found: "%s"\n'
OSError: No wkhtmltopdf executable found: "b''"
If this file exists please check that this process can read it or you can pass path to it manually in method call, check README. Otherwise please install wkhtmltopdf - https://github.com/JazzCore/python-pdfkit/wiki/Installing-wkhtmltopdf
2024-11-03 22:33:41,004 - werkzeug - INFO - 127.0.0.1 - - [03/Nov/2024 22:33:41] "[35m[1mPOST /generate_document HTTP/1.1[0m" 500 -
2024-11-04 10:34:40,417 - root - INFO - Static directories created successfully
2024-11-04 10:34:40,423 - root - INFO - Static directories created successfully
2024-11-04 10:34:40,471 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:34:40,474 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:34:43,800 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:34:43] "GET / HTTP/1.1" 200 -
2024-11-04 10:34:44,372 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:34:44] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:34:44,377 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:34:44] "GET /static/css/styles.css HTTP/1.1" 200 -
2024-11-04 10:35:02,428 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:35:02] "GET / HTTP/1.1" 200 -
2024-11-04 10:35:02,558 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:35:02] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:35:02,565 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:35:02] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:37:33,621 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:33] "GET / HTTP/1.1" 200 -
2024-11-04 10:37:33,657 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:33] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:37:33,675 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:33] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:37:43,866 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:43] "GET / HTTP/1.1" 200 -
2024-11-04 10:37:43,970 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:43] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:37:43,971 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:43] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:37:55,229 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:55] "GET / HTTP/1.1" 200 -
2024-11-04 10:37:55,277 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:55] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:37:55,293 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:37:55] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:40:48,590 - root - INFO - Static directories created successfully
2024-11-04 10:40:48,595 - root - INFO - Static directories created successfully
2024-11-04 10:40:48,642 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:40:48,647 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:40:52,288 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:40:52] "GET / HTTP/1.1" 200 -
2024-11-04 10:40:52,537 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:40:52] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:40:52,548 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:40:52] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:41:06,737 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:41:06] "GET / HTTP/1.1" 200 -
2024-11-04 10:41:06,932 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:41:06] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:41:06,932 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:41:06] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:43:10,985 - root - INFO - Static directories created successfully
2024-11-04 10:43:10,989 - root - INFO - Static directories created successfully
2024-11-04 10:43:11,014 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:43:11,018 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:43:14,236 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:43:14] "GET / HTTP/1.1" 200 -
2024-11-04 10:43:14,448 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:43:14] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:43:14,450 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:43:14] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:44:38,247 - root - INFO - Static directories created successfully
2024-11-04 10:44:38,252 - root - INFO - Static directories created successfully
2024-11-04 10:44:38,272 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:44:38,273 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:44:39,567 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:44:39] "GET / HTTP/1.1" 200 -
2024-11-04 10:44:39,736 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:44:39] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:44:39,744 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:44:39] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:50:43,969 - root - INFO - Static directories created successfully
2024-11-04 10:50:43,980 - root - INFO - Static directories created successfully
2024-11-04 10:50:44,027 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:50:44,029 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:50:45,450 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:50:45] "GET / HTTP/1.1" 200 -
2024-11-04 10:50:45,874 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:50:45] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:50:45,878 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:50:45] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:51:19,224 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:51:19] "GET / HTTP/1.1" 200 -
2024-11-04 10:51:19,274 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:51:19] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:51:19,289 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:51:19] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 10:55:48,662 - root - INFO - Static directories created successfully
2024-11-04 10:55:48,667 - root - INFO - Static directories created successfully
2024-11-04 10:55:48,685 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:55:48,686 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:55:50,796 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:55:50] "GET / HTTP/1.1" 200 -
2024-11-04 10:55:51,032 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:55:51] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:55:51,032 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:55:51] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:56:01,473 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:56:01] "GET / HTTP/1.1" 200 -
2024-11-04 10:56:01,627 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:56:01] "GET /static/css/styles.css HTTP/1.1" 200 -
2024-11-04 10:56:01,628 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:56:01] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:56:02,141 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:56:02] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-11-04 10:57:34,978 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:57:34] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:59:41,571 - root - INFO - Static directories created successfully
2024-11-04 10:59:41,576 - root - INFO - Static directories created successfully
2024-11-04 10:59:41,623 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 10:59:41,624 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 10:59:45,024 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:59:45] "GET / HTTP/1.1" 200 -
2024-11-04 10:59:45,344 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:59:45] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 10:59:45,356 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:59:45] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 10:59:54,561 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 10:59:54] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 11:03:24,680 - root - INFO - Static directories created successfully
2024-11-04 11:03:24,691 - root - INFO - Static directories created successfully
2024-11-04 11:03:24,733 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 11:03:24,736 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 11:03:26,522 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:03:26] "GET / HTTP/1.1" 200 -
2024-11-04 11:03:26,997 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:03:26] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 11:03:27,001 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:03:27] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 11:03:49,571 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:03:49] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 11:03:56,004 - __main__ - INFO - Received XML content for analysis
2024-11-04 11:03:56,005 - __main__ - DEBUG - Starting XML parsing
2024-11-04 11:03:56,012 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:03:56] "POST /analyze HTTP/1.1" 200 -
2024-11-04 11:06:31,029 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:06:31] "POST /generate_document HTTP/1.1" 200 -
2024-11-04 11:07:11,477 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:11] "GET / HTTP/1.1" 200 -
2024-11-04 11:07:11,535 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:11] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 11:07:11,558 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:11] "GET /static/js/main.js HTTP/1.1" 200 -
2024-11-04 11:07:29,928 - root - INFO - Static directories created successfully
2024-11-04 11:07:29,935 - root - INFO - Static directories created successfully
2024-11-04 11:07:29,976 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.0.106:5000
2024-11-04 11:07:29,979 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-11-04 11:07:33,223 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:33] "GET / HTTP/1.1" 200 -
2024-11-04 11:07:33,566 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:33] "[36mGET /static/js/main.js HTTP/1.1[0m" 304 -
2024-11-04 11:07:33,593 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:33] "[36mGET /static/css/styles.css HTTP/1.1[0m" 304 -
2024-11-04 11:07:47,182 - __main__ - INFO - Received XML content for analysis
2024-11-04 11:07:47,183 - __main__ - DEBUG - Starting XML parsing
2024-11-04 11:07:47,186 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:07:47] "POST /analyze HTTP/1.1" 200 -
2024-11-04 11:08:11,686 - werkzeug - INFO - 127.0.0.1 - - [04/Nov/2024 11:08:11] "POST /generate_document HTTP/1.1" 200 -
