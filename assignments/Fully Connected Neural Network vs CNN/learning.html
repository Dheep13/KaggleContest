<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Neural Network Comparison: Fully Connected vs CNN</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1, h2, h3 {
            color: #2c3e50;
        }
        .example, .component, .comparison {
            background-color: #f0f0f0;
            border-left: 4px solid #3498db;
            padding: 10px;
            margin: 20px 0;
        }
        .comparison {
            border-color: #e74c3c;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
    </style>
</head>
<body>
    <h1>Neural Network Comparison: Fully Connected vs CNN</h1>
    
    <p>This document compares Fully Connected Neural Networks and Convolutional Neural Networks (CNNs), with a focus on their application to the MNIST digit recognition task.</p>
    
    <div class="comparison">
        <h2>Visual Comparison: Fully Connected vs CNN</h2>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 400">
          <!-- SVG content from the previous artifact -->
          <!-- Fully Connected Network -->
          <g transform="translate(50, 50)">
            <text x="150" y="-20" text-anchor="middle" font-weight="bold">Fully Connected Network</text>
            
            <!-- Input Layer -->
            <circle cx="0" cy="0" r="20" fill="#6ab04c" />
            <circle cx="0" cy="75" r="20" fill="#6ab04c" />
            <circle cx="0" cy="150" r="20" fill="#6ab04c" />
            <text x="-40" y="75" text-anchor="end" alignment-baseline="middle">Input</text>
            
            <!-- Hidden Layer -->
            <circle cx="150" cy="0" r="20" fill="#f9ca24" />
            <circle cx="150" cy="75" r="20" fill="#f9ca24" />
            <circle cx="150" cy="150" r="20" fill="#f9ca24" />
            <text x="150" y="190" text-anchor="middle">Hidden</text>
            
            <!-- Output Layer -->
            <circle cx="300" cy="37.5" r="20" fill="#eb4d4b" />
            <circle cx="300" cy="112.5" r="20" fill="#eb4d4b" />
            <text x="340" y="75" text-anchor="start" alignment-baseline="middle">Output</text>
            
            <!-- Connections -->
            <g stroke="#000" stroke-width="1" opacity="0.2">
              <line x1="20" y1="0" x2="130" y2="0" />
              <line x1="20" y1="0" x2="130" y2="75" />
              <line x1="20" y1="0" x2="130" y2="150" />
              <line x1="20" y1="75" x2="130" y2="0" />
              <line x1="20" y1="75" x2="130" y2="75" />
              <line x1="20" y1="75" x2="130" y2="150" />
              <line x1="20" y1="150" x2="130" y2="0" />
              <line x1="20" y1="150" x2="130" y2="75" />
              <line x1="20" y1="150" x2="130" y2="150" />
              
              <line x1="170" y1="0" x2="280" y2="37.5" />
              <line x1="170" y1="0" x2="280" y2="112.5" />
              <line x1="170" y1="75" x2="280" y2="37.5" />
              <line x1="170" y1="75" x2="280" y2="112.5" />
              <line x1="170" y1="150" x2="280" y2="37.5" />
              <line x1="170" y1="150" x2="280" y2="112.5" />
            </g>
          </g>
          
          <!-- CNN -->
          <g transform="translate(50, 300)">
            <text x="150" y="-20" text-anchor="middle" font-weight="bold">Convolutional Neural Network (CNN)</text>
            
            <!-- Input Layer -->
            <rect x="0" y="0" width="60" height="60" fill="#6ab04c" />
            <text x="-10" y="30" text-anchor="end" alignment-baseline="middle">Input</text>
            
            <!-- Convolutional Layer -->
            <rect x="100" y="10" width="40" height="40" fill="#f9ca24" />
            <text x="120" y="70" text-anchor="middle">Conv</text>
            
            <!-- Pooling Layer -->
            <rect x="180" y="15" width="30" height="30" fill="#22a6b3" />
            <text x="195" y="70" text-anchor="middle">Pool</text>
            
            <!-- Fully Connected Layer -->
            <circle cx="250" cy="15" r="15" fill="#be2edd" />
            <circle cx="250" cy="45" r="15" fill="#be2edd" />
            <text x="250" y="80" text-anchor="middle">FC</text>
            
            <!-- Output Layer -->
            <circle cx="310" cy="30" r="15" fill="#eb4d4b" />
            <text x="340" y="30" text-anchor="start" alignment-baseline="middle">Output</text>
            
            <!-- Connections -->
            <line x1="60" y1="30" x2="100" y2="30" stroke="#000" stroke-width="2" />
            <line x1="140" y1="30" x2="180" y2="30" stroke="#000" stroke-width="2" />
            <line x1="210" y1="30" x2="235" y2="30" stroke="#000" stroke-width="2" />
            <line x1="265" y1="30" x2="295" y2="30" stroke="#000" stroke-width="2" />
          </g>
        </svg>
        
        <h3>Key Differences:</h3>
        <ul>
            <li><strong>Structure:</strong> FCNs have uniform fully connected layers, while CNNs have specialized layers (convolutional, pooling, fully connected).</li>
            <li><strong>Connections:</strong> FCNs connect every neuron to every neuron in adjacent layers. CNNs have more localized connections, especially in early layers.</li>
            <li><strong>Spatial awareness:</strong> CNNs preserve spatial relationships in the data, crucial for tasks like image recognition.</li>
            <li><strong>Efficiency:</strong> CNNs are generally more efficient for spatial data due to parameter sharing in convolutional layers.</li>
        </ul>
    </div>

    <h2>MNIST Digit Recognition: FCN vs CNN Approach</h2>
    
    <div class="example">
        <h3>Fully Connected Network Approach:</h3>
        <p>A fully connected network for MNIST digit recognition might look like this:</p>
        
        <ul>
            <li>Input Layer: 784 neurons (28x28 pixel image flattened)</li>
            <li>Hidden Layer 1: 128 neurons with ReLU activation</li>
            <li>Hidden Layer 2: 64 neurons with ReLU activation</li>
            <li>Output Layer: 10 neurons with Softmax activation</li>
        </ul>
        
        <p>In this fully connected network:</p>
        <ol>
            <li>The input layer receives flattened pixel values from a 28x28 image of a handwritten digit.</li>
            <li>Each hidden layer processes and transforms the information, using ReLU activation to introduce non-linearity.</li>
            <li>The output layer uses Softmax activation to produce a probability distribution over the 10 possible digits.</li>
            <li>The digit with the highest probability is the network's prediction.</li>
        </ol>
        <p>This approach doesn't explicitly consider the spatial structure of the image.</p>
    </div>

    <div class="example">
        <h3>CNN Approach:</h3>
        <p>A CNN for MNIST digit recognition would typically have this structure:</p>
        
        <ul>
            <li>Input Layer: 28x28x1 (image width x height x channels)</li>
            <li>Convolutional Layer 1: 32 filters of size 3x3, ReLU activation</li>
            <li>Max Pooling Layer 1: 2x2 pool size</li>
            <li>Convolutional Layer 2: 64 filters of size 3x3, ReLU activation</li>
            <li>Max Pooling Layer 2: 2x2 pool size</li>
            <li>Flatten Layer: Converts 2D feature maps to 1D feature vector</li>
            <li>Fully Connected Layer: 128 neurons, ReLU activation</li>
            <li>Output Layer: 10 neurons with Softmax activation</li>
        </ul>
        
        <p>In this CNN:</p>
        <ol>
            <li>Convolutional layers apply filters to detect features like edges, curves, and more complex patterns.</li>
            <li>Pooling layers reduce the spatial dimensions, making the network more computationally efficient and helping it focus on the most important features.</li>
            <li>The flatten layer transitions from the 2D structure of convolutional layers to the 1D structure needed for fully connected layers.</li>
            <li>The fully connected layer combines these high-level features for final classification.</li>
            <li>The output layer produces probabilities for each digit, just like in the FCN.</li>
        </ol>
        <p>This approach explicitly considers and preserves the spatial structure of the image throughout most of the network.</p>
    </div>

    <h3>Comparison for MNIST Task:</h3>
    <ul>
        <li><strong>Feature Extraction:</strong> CNNs automatically learn to extract relevant features from the images, while FCNs rely on the network to learn appropriate representations from flattened input.</li>
        <li><strong>Parameter Efficiency:</strong> CNNs typically require fewer parameters due to weight sharing in convolutional layers, making them less prone to overfitting on tasks like MNIST.</li>
        <li><strong>Spatial Information:</strong> CNNs maintain spatial relationships between pixels, which is crucial for recognizing patterns in handwritten digits.</li>
        <li><strong>Performance:</strong> For image-based tasks like MNIST, CNNs generally achieve higher accuracy with fewer parameters compared to FCNs.</li>
    </ul>

    <p>While both network types can perform the MNIST digit recognition task, CNNs are generally preferred for image-based tasks due to their ability to efficiently capture and utilize spatial information.</p>

</body>
</html>