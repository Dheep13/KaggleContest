{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "fULe8K_SxRw3",
        "outputId": "55ba93c8-ea71-44c2-8e41-d430e7e041b5"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# This will prompt you to select the kaggle.json file\n",
        "files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSGIKB_U3hqt"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peFEmfmr3_Ls",
        "outputId": "f42a6f4d-9a84-408f-c5b0-3ea1da057825"
      },
      "outputs": [],
      "source": [
        "# !pip install kaggle\n",
        "!kaggle competitions download -c bird-classification-competition\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNTmW4Ke59tr"
      },
      "outputs": [],
      "source": [
        "!unzip -q bird-classification-competition.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMCCEuvw6bx0",
        "outputId": "09cd4875-4b53-4ff7-ff4a-ad178f351e1d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# For CSV files\n",
        "df = pd.read_csv('Upload/Upload/train.csv')\n",
        "print(df.head())\n",
        "print(os.getcwd())\n",
        "!ls content/Upload/Upload\n",
        "\n",
        "!ls 'content/Upload/Upload/valid/ABBOTTS BABBLER'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqYLd7RT7wsM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5x_uJmc75P_",
        "outputId": "d9df1383-c59b-427a-ebd6-b135c0aedb74"
      },
      "outputs": [],
      "source": [
        "# normalization\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# Assuming datasets are stored in folders named 'train', 'test', 'val'\n",
        "train_dataset = ImageFolder(root='/content/Upload/Upload/train', transform=transform)\n",
        "val_dataset = ImageFolder(root='/content/Upload/Upload/valid', transform=transform)\n",
        "test_dataset = ImageFolder(root='/content/Upload/Upload/test', transform=transform)\n",
        "\n",
        "num_classes = len(test_dataset.class_to_idx)\n",
        "print(f\"Number of classes in the test dataset: {num_classes}\")\n",
        "\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64  # You can adjust this according to your GPU memory\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcM-OvjyAUpw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Calculation:\n",
        "# Input size: 224x224\n",
        "# After 1st pooling: 112x112 (since stride=2)\n",
        "# After 2nd pooling: 56x56\n",
        "# After 3rd pooling: 28x28\n",
        "# If the final convolutional layer has 64 output channels, then the total number of features going into the fully connected layer is 64 * 28 * 28.\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes=525):  # Setting the number of classes based on your dataset\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        # Adjusted dimensions based on pooling layers\n",
        "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)  # Output layer adjusted for 525 classes\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # Flatten the tensor for the fully connected layer\n",
        "        x = x.view(-1, 64 * 28 * 28)  # Adjusted for the output size of the last pooling layer\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNowZjAtCJNc",
        "outputId": "4408cf99-e143-46ce-988d-6b56accc635f"
      },
      "outputs": [],
      "source": [
        "# Example using a pre-trained ResNet model\n",
        "model = torchvision.models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 525)  # Adjust the number of output classes to match your dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFhFzIIdBP_O",
        "outputId": "ea699f0b-e3ff-434f-e64b-bb32c7c51976"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCXWwlB1BTtO",
        "outputId": "c984c0de-7bc6-4ab4-8fcd-13fb5f471998"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "for epoch in range(10):  # Number of epochs can be adjusted\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0].to(device), data[1].to(device)#If you're training on a GPU, you would set device = torch.device(\"cuda:0\") to specify the first GPU as your device. Then, using .to(device) ensures all your computations happen on that GPU.\n",
        "# For example : Let's say you're training a neural network to classify images of cats and dogs. Your training dataset consists of 1000 images, and you've set your batch size to 100. This means train_loader will yield 10 batches, each containing 100 images and their corresponding labels.\n",
        "# In the first iteration of the loop, i is 0 (the first batch), and data contains the first batch of 100 images and their 100 labels.\n",
        "# data[0] is a tensor of shape [100, C, H, W] (assuming each image has C channels, height H, and width W). This represents the 100 images in the batch.\n",
        "# data[1] is a tensor of shape [100], representing the labels (e.g., 0 for cat, 1 for dog) for each of the 100 images.\n",
        "        optimizer.zero_grad()#optimizer.zero_grad() ensures that the gradient calculations are correct for each batch by clearing the old gradients, preventing them from accumulating across batches.\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()# gradient of the loss function with respect to that parameter. This is done using the chain rule of calculus, working backwards from the output layer to the input layer (hence \"backward pass\").\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:  # Print average loss every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_wsZkhG0hxu",
        "outputId": "fa6c9f66-7b10-4f87-92fb-a35a9877a9ad"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "model_save_name = 'classifier_11feb.pt'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\"  # Adjust the path based on where you want to save in Google Drive\n",
        "torch.save(model.state_dict(), path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "TMM210iYPZe_",
        "outputId": "2e8e8e5f-682d-4b60-cf6b-8413e81627a3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Load the validation dataset CSV file\n",
        "val_csv_path = '/content/Upload/Upload/val.csv'  # Adjust this path as needed\n",
        "val_df = pd.read_csv(val_csv_path)\n",
        "\n",
        "# Create a dictionary mapping file paths to IDs\n",
        "file_path_to_id = {row['filepaths']: row['ID'] for index, row in val_df.iterrows()}\n",
        "\n",
        "# Assuming model, val_loader, and device are already defined\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "# Define the prefix that needs to be removed from paths in val_loader to match the CSV\n",
        "prefix_to_remove = '/content/Upload/Upload/'\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "        # Accumulate all the predictions and labels\n",
        "        all_predictions.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the network on the validation images: {accuracy:.2f}%')\n",
        "\n",
        "# Calculate precision, recall, and F1 score using sklearn\n",
        "precision = precision_score(all_targets, all_predictions, average='weighted')\n",
        "recall = recall_score(all_targets, all_predictions, average='weighted')\n",
        "f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.3f}')\n",
        "print(f'Recall: {recall:.3f}')\n",
        "print(f'F1 Score: {f1:.3f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJfT9muNf2-X",
        "outputId": "94feda23-7f6b-4979-c703-a0267be877bd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbzblgeBhUh7"
      },
      "outputs": [],
      "source": [
        "!ls \"/content/drive/My Drive/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sYxXE-7n0ht",
        "outputId": "6e730ad5-1a9c-4e49-911f-ef8b9730d20c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Automatically use GPU if available, otherwise fallback to CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Specify the exact path to the saved model\n",
        "model_path = '/content/drive/My Drive/classifier_11feb.pt'\n",
        "\n",
        "# Initialize the pre-trained ResNet50 model architecture\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# If you modified the final layer of the model, replicate that modification\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, 525)  # Adjust this to match the number of classes in your dataset\n",
        "\n",
        "# Load the saved model weights. If using GPU, 'map_location' is not needed. It automatically maps to the current device.\n",
        "model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "\n",
        "# Move the model to the selected device\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVxE06EEANcm",
        "outputId": "4823f3ed-cfe3-47e7-a6f3-db37bc251568"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "\n",
        "# Define batch_size\n",
        "# batch_size = 32  # Or any other size that fits your needs\n",
        "\n",
        "# normalization--same as when training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize the images to 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the validation dataset\n",
        "val_dataset = datasets.ImageFolder(root='/content/Upload/Upload/test', transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Load the CSV file containing the file paths\n",
        "val_csv_path = '/content/Upload/Upload/test.csv'  # Adjust if necessary\n",
        "val_df = pd.read_csv(val_csv_path)\n",
        "\n",
        "# Copy the original filepaths to a new column for comparison\n",
        "val_df['original_filepaths'] = val_df['filepaths']\n",
        "\n",
        "# Replace the filepaths that start with the specified pattern\n",
        "val_df['filepaths'] = val_df['filepaths'].str.replace(r'^test/PARAKETT\\s+AKULET/', 'test/PARAKETT  AUKLET/', regex=True)\n",
        "\n",
        "# Identify the filepaths that have changed\n",
        "changed_filepaths = val_df[val_df['filepaths'] != val_df['original_filepaths']]\n",
        "\n",
        "# Print all filepaths that changed\n",
        "for index, row in changed_filepaths.iterrows():\n",
        "    print(f\"Original: {row['original_filepaths']} -> Updated: {row['filepaths']}\")\n",
        "\n",
        "# Save the changes back to val.csv\n",
        "val_df.to_csv(val_csv_path, index=False)\n",
        "\n",
        "\n",
        "# Set the base path where the images are stored\n",
        "base_path = '/content/Upload/Upload'  # Replace with the base path to your image directories\n",
        "\n",
        "# Prepare the submission DataFrame\n",
        "submission_df = pd.DataFrame(columns=['ID', 'ClassificationID'])\n",
        "\n",
        "# # Loop through the file paths in the val.csv and make predictions\n",
        "for index, row in val_df.iterrows():\n",
        "    # Construct the full image path\n",
        "    image_path = os.path.join(base_path, row['filepaths'])\n",
        "\n",
        "    try:\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        # Transform the image\n",
        "        image = transform(image)\n",
        "        # Add a batch dimension\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "        # Predict the class\n",
        "        with torch.no_grad():\n",
        "            outputs = model(image)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            print([row['ID'], predicted.item()])\n",
        "        # Append the ID and predicted class ID to the submission dataframe\n",
        "        submission_df = submission_df.append({'ID': row['ID'], 'ClassificationID': predicted.item()}, ignore_index=True)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred with image {image_path}: {e}\")\n",
        "\n",
        "# Save the new submission DataFrame to a CSV file\n",
        "submission_path = '/content/drive/My Drive/submission_11feb_new.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "print(f\"New submission file saved to {submission_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ganf1CPqYX-0",
        "outputId": "dbaef912-ef79-48a1-9745-f10fe343301a"
      },
      "outputs": [],
      "source": [
        "# Make sure the submission DataFrame has the same length as val_df\n",
        "assert len(submission_df) == len(val_df), \"Submission length does not match\"\n",
        "# Sort the submission DataFrame based on the ID column to ensure correct order\n",
        "submission_df.sort_values('ID', inplace=True)\n",
        "# Reset the index to avoid any potential issues with indexing\n",
        "submission_df.reset_index(drop=True, inplace=True)\n",
        "# Save the submission DataFrame to a CSV file\n",
        "submission_df.to_csv(submission_path, index=False)\n",
        "print(f\"Submission file saved to {submission_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4uQQqTYFZpK"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "model_save_name = 'classifier_11feb.pt'\n",
        "path = F\"/content/drive/My Drive/{model_save_name}\"  \n",
        "torch.save(model.state_dict(), path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
