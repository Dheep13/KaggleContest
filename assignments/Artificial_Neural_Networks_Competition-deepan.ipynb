{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"executionInfo":{"elapsed":22401,"status":"ok","timestamp":1709526695824,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"h3SGoExDui89","outputId":"4080dfb7-5369-4465-d4e5-34e657e14da1"},"outputs":[],"source":["from google.colab import files\n","\n","# This will prompt you to select the kaggle.json file\n","files.upload()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1709526930349,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"5s17001bunjy"},"outputs":[],"source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1447,"status":"ok","timestamp":1709526934847,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"K3ApVJHvurbr","outputId":"8d6e42a3-5e0b-420b-d784-69e2035ffba4"},"outputs":[],"source":["!kaggle competitions download -c copy-of-artificial-neural-networks-competition --force"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24976,"status":"ok","timestamp":1709527276176,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"IHxSPIt9wk0m","outputId":"0f5fe61e-de4a-4c74-b13c-56948436bcfa"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2146,"status":"ok","timestamp":1709527377483,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"HYTsQpn-xCyW","outputId":"c93dd0a7-4b84-4ac8-c5ce-b04dbd8ec66b"},"outputs":[],"source":["!unzip '/content/drive/My Drive/Colab Notebooks/copy-of-artificial-neural-networks-competition.zip' -d '/content/dataset'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":568},"executionInfo":{"elapsed":969,"status":"ok","timestamp":1709527485075,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"sB70NKA2xfHm","outputId":"84bc21d0-9861-48fd-82c7-1e21aa57881a"},"outputs":[],"source":["import pandas as pd\n","\n","# Adjust the filename and path as necessary\n","file_path = '/content/dataset/train_mpst.csv'  # Example for accessing the training dataset\n","train_df = pd.read_csv(file_path)\n","train_df.head()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14753,"status":"ok","timestamp":1709528806791,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"ABqKMmMUyStg","outputId":"1dec2a39-c0a5-4c5f-fa59-544e01c63098"},"outputs":[],"source":["# Step 2: Data Cleaning and Preprocessing\n","import re\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Download NLTK data (you may skip this if you've already done it)\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Function to clean text data\n","def clean_text(text):\n","    # Remove HTML tags\n","    text = re.sub(r'<[^>]*>', '', text)\n","    # Remove punctuation and numbers\n","    text = re.sub('[^a-zA-Z]', ' ', text)\n","    # Convert text to lowercase\n","    text = text.lower()\n","    # Remove extra spaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text\n","\n","# Apply the cleaning function to the plot_synopsis column\n","train_df['cleaned_plot'] = train_df['plot_synopsis'].apply(clean_text)\n","\n","# Step 3: Text Vectorization (TF-IDF)\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Initialize TF-IDF Vectorizer\n","tfidf_vectorizer = TfidfVectorizer(max_features=10000, stop_words='english')\n","\n","# Fit and transform the cleaned plot synopsis text\n","X_tfidf = tfidf_vectorizer.fit_transform(train_df['cleaned_plot'])\n","\n","# For multi-label classification, ensure labels are properly encoded\n","# Assuming labels are in separate columns following 'plot_synopsis', 'imdb_id', etc.\n","# Convert DataFrame label columns to a list of lists\n","\n","# Assuming the DataFrame 'train_df' holds your data, and label columns are correctly identified\n","label_columns = train_df.columns[4:75]  # Adjust indices as necessary\n","labels_list = train_df[label_columns].apply(lambda row: row.index[row == 1].tolist(), axis=1)\n","labels = train_df[label_columns]\n","mlb = MultiLabelBinarizer()\n","y = mlb.fit_transform(labels_list)\n","\n","print(y.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( X_tfidf.shape)  # Should now match the number of rows in 'X_tfidf'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":444,"status":"ok","timestamp":1709537312188,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"rVFDu3no1IYw","outputId":"d3bf5379-8943-4990-9e51-e27aabd26b49"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n","\n","print(X_train.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( y_val.shape)  # Should now match the number of rows in 'X_tfidf'\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3690,"status":"ok","timestamp":1709537365631,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"r9kbC4fe3FeT","outputId":"4767f814-0822-45d6-9ae8-a0529df0e488"},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","from scipy.sparse import csr_matrix\n","\n","# Convert the Scipy sparse matrix to a dense NumPy array\n","# This step is necessary because PyTorch doesn't support sparse matrices as input for fully connected layers directly\n","X_train_dense = X_train.toarray() if isinstance(X_train, csr_matrix) else X_train\n","X_val_dense = X_val.toarray() if isinstance(X_val, csr_matrix) else X_val\n","\n","# Convert data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train_dense, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_val_tensor = torch.tensor(X_val_dense, dtype=torch.float32)\n","y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n","\n","# Create TensorDatasets\n","train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","\n","# Create DataLoaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","print(X_train_tensor.shape)  # Should now match the number of rows in 'X_tfidf'\n","print( X_val_tensor.shape)  # Should now match the number of rows in 'X_tfidf'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1709529011259,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"NHp73KBx3odi"},"outputs":[],"source":["from torch import nn\n","\n","class MultiLabelNN(nn.Module):\n","    def __init__(self, num_features, num_labels):\n","        super(MultiLabelNN, self).__init__()\n","        self.layer1 = nn.Linear(num_features, 512)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(0.5)\n","        self.layer2 = nn.Linear(512, 256)\n","        self.output_layer = nn.Linear(256, num_labels)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.relu(self.layer1(x))\n","        x = self.dropout(x)\n","        x = self.relu(self.layer2(x))\n","        x = self.dropout(x)\n","        x = self.sigmoid(self.output_layer(x))\n","        return x\n","\n","# Instantiate the model\n","num_features = X_train.shape[1]\n","num_labels = y_train.shape[1]\n","model = MultiLabelNN(num_features, num_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":140113,"status":"ok","timestamp":1709533799568,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"nTlIZHoEJWzb","outputId":"c87056e8-c660-4cac-e593-4a64e0022f4e"},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCELoss()\n","\n","# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    for X_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","    print(f'Epoch {epoch+1}, Loss: {train_loss / len(train_loader)}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":169369,"status":"ok","timestamp":1709533986474,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"KzmnQPolJyky","outputId":"6d613bc4-4ad7-4f5c-bcd1-7a77f6a755b2"},"outputs":[],"source":["import time\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","criterion = nn.BCELoss()\n","\n","num_epochs = 20\n","\n","# Start time of the training\n","start_time = time.time()\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    epoch_start_time = time.time()  # Start time of the current epoch\n","\n","    for X_batch, y_batch in train_loader:\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","\n","    epoch_duration = time.time() - epoch_start_time\n","    total_estimated_time = epoch_duration * num_epochs\n","    time_elapsed = time.time() - start_time\n","    time_remaining = total_estimated_time - time_elapsed\n","\n","    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {train_loss / len(train_loader)}, Time elapsed: {time_elapsed:.2f}s, Estimated time remaining: {time_remaining:.2f}s')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":940,"status":"ok","timestamp":1709534502665,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"vOT39rsLMjHk","outputId":"24a2bdb0-5d89-4c6b-f186-22053c91004e"},"outputs":[],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, hamming_loss\n","import numpy as np\n","\n","# Ensure model is in evaluation mode\n","model.eval()\n","\n","# Containers for predictions and true labels\n","all_preds = []\n","all_true_labels = []\n","\n","# No gradient is needed for evaluation\n","with torch.no_grad():\n","    for X_batch, y_batch in val_loader:\n","        outputs = model(X_batch)\n","        # Convert model outputs to binary values (0 or 1)\n","        predicted = (outputs > 0.5).int()\n","        all_preds.append(predicted)\n","        all_true_labels.append(y_batch.int())\n","\n","# Concatenate all batches\n","all_preds = torch.cat(all_preds, dim=0).cpu().numpy()\n","all_true_labels = torch.cat(all_true_labels, dim=0).cpu().numpy()\n","\n","# Calculate metrics\n","f1 = f1_score(all_true_labels, all_preds, average='micro')\n","precision = precision_score(all_true_labels, all_preds, average='micro')\n","recall = recall_score(all_true_labels, all_preds, average='micro')\n","hammingloss = hamming_loss(all_true_labels, all_preds)\n","\n","print(f'Precision: {precision:.4f}')\n","print(f'Recall: {recall:.4f}')\n","print(f'F1 Score: {f1:.4f}')\n","print(f'Hamming Loss: {hammingloss:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7563,"status":"ok","timestamp":1709534749347,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"AYpoHj0uNLnM"},"outputs":[],"source":["# Assuming you've defined a preprocessing function similar to `clean_text` previously\n","\n","test_file_path = '/content/dataset/test.csv'\n","\n","test_df = pd.read_csv(test_file_path)\n","test_df['processed_plot'] = test_df['plot_synopsis'].apply(clean_text)\n","\n","# Vectorize the processed text using the same TF-IDF vectorizer you used for training\n","# IMPORTANT: Use transform() NOT fit_transform(), as you want to use the same vocabulary as your training set\n","X_test_tfidf = tfidf_vectorizer.transform(test_df['processed_plot'])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1740,"status":"ok","timestamp":1709534772651,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"uJtAq5DRNj8b"},"outputs":[],"source":["X_test_tensor = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)  # Convert to tensor\n","test_dataset = TensorDataset(X_test_tensor)  # Create dataset without labels\n","test_loader = DataLoader(test_dataset, batch_size=64)  # Create DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2889,"status":"ok","timestamp":1709538426050,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"cVrCkzvBNqHe","outputId":"331d2404-c55f-4ee8-e2ff-3b70f4d8b4f7"},"outputs":[],"source":["model.eval()  # Set the model to evaluation mode\n","test_preds = []\n","\n","with torch.no_grad():\n","    for X_batch, in test_loader:\n","        outputs = model(X_batch)\n","        predicted = (outputs > 0.5).int()  # Apply threshold to get binary predictions\n","        print(predicted.shape)  # Check the shape of predictions per batch\n","        test_preds.append(predicted)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1709538889961,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"TSZg565tOtYF","outputId":"afb271f0-94d1-4a2c-eb06-5012f039d416"},"outputs":[],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","# Assuming `test_preds` contains the binary predictions for the test dataset\n","\n","# Concatenate all batch predictions\n","test_preds_concatenated = torch.cat(tuple(test_preds), dim=0)\n","\n","print(test_preds_concatenated.shape)\n","\n","# Assuming you have the test DataFrame loaded for 'ID' mapping\n","test_df = pd.read_csv(test_file_path)\n","\n","# Assuming your test DataFrame has an 'ID' column that matches the sample submission\n","# If your DataFrame uses a different column name for IDs, adjust 'imdb_id' accordingly\n","ids = test_df['imdb_id'].values\n","\n","\n","# Load the sample submission file again\n","sample_submission_path = '/content/dataset/sample_submission.csv'  # Adjust this path if necessary\n","sample_submission_df = pd.read_csv(sample_submission_path)\n","\n","print( test_preds_concatenated.shape)\n","\n","\n","# Convert binary predictions to a DataFrame\n","# The column names for predictions should match those in the sample submission, excluding the 'ID' column\n","label_columns = sample_submission_df.columns[1:]  # Exclude the 'ID' column\n","predictions_df = pd.DataFrame(test_preds_concatenated.numpy(), columns=label_columns)\n","\n","# Insert the 'ID' column at the beginning of the DataFrame\n","predictions_df.insert(0, 'ID', ids)\n","\n","# Ensure the format matches the sample submission by converting to float\n","# This step may be optional depending on the requirements of the submission platform\n","# predictions_df = predictions_df.astype(float)\n","\n","submission_file_path = '/content/dataset/final_submission.csv'\n","# Save the DataFrame to a CSV file\n","predictions_df.to_csv(submission_file_path, index=False)\n","\n","# Output the path to the saved submission file\n","submission_file_path\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPy/cGJmNuwcUpj/Ya+L510","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
